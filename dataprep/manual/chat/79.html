<!DOCTYPE html>
<!-- saved from url=(0066)https://chat.openai.com/share/51b5e459-6956-4591-b8a9-beeae0401063 -->
<html data-build="prod-23c601c" class="light" lang="en-US" style="color-scheme: light;"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="apple-touch-icon" sizes="180x180" href="https://cdn.oaistatic.com/_next/static/media/apple-touch-icon.59f2e898.png"><link rel="icon" type="image/png" sizes="32x32" href="https://cdn.oaistatic.com/_next/static/media/favicon-32x32.be48395e.png"><link rel="icon" type="image/png" sizes="16x16" href="https://cdn.oaistatic.com/_next/static/media/favicon-16x16.9b8dbb69.png"><link rel="preconnect" href="https://cdn.oaistatic.com/"><title>ChatGPT - ELIZA</title><meta name="keywords" content="ai chat,ai,chap gpt,chat gbt,chat gpt 3,chat gpt login,chat gpt website,chat gpt,chat gtp,chat openai,chat,chatai,chatbot gpt,chatg,chatgpt login,chatgpt,gpt chat,open ai,openai chat,openai chatgpt,openai"><meta name="apple-itunes-app" content="app-id=6448311069"><meta property="og:site_name" content="ChatGPT"><meta name="robots" content="noindex,nofollow"><meta name="title" content="ChatGPT - ELIZA"><meta property="og:site_name" content="ChatGPT"><meta property="og:type" content="website"><meta property="og:title" content="ChatGPT - ELIZA"><meta property="og:url" content="/g/g-8iui73B2J-eliza"><meta name="description" content="Python Sage &amp; Jungian Psychology Enthusiast"><meta property="og:description" content="Python Sage &amp; Jungian Psychology Enthusiast"><meta property="og:image" content="https://files.oaiusercontent.com/file-FKZ1N0SqdXDiQK0iLICAEdPZ?se=2123-11-16T12%3A55%3A29Z&amp;sp=r&amp;sv=2021-08-06&amp;sr=b&amp;rscc=max-age%3D1209600%2C%20immutable&amp;rscd=attachment%3B%20filename%3D0d3c6b58-2d37-4f76-887e-5565d3b760fb.png&amp;sig=uoID9C2n0e5MqIOy0U9loaCLqpkqwYv5G91QA8wDIxk%3D"><meta property="og:image:width" content="512"><meta property="og:image:height" content="512"><meta name="next-head-count" content="22"><link rel="preload" href="https://cdn.oaistatic.com/_next/static/media/soehne-buch.13189857.woff2" as="font" crossorigin=""><link rel="preload" href="https://cdn.oaistatic.com/_next/static/media/soehne-halbfett.977f1845.woff2" as="font" crossorigin=""><link rel="preload" href="https://cdn.oaistatic.com/_next/static/media/soehne-mono-buch.de677af1.woff2" as="font" crossorigin=""><link rel="preload" href="https://cdn.oaistatic.com/_next/static/media/soehne-mono-halbfett.b082e8e2.woff2" as="font" crossorigin=""><link data-next-font="" rel="preconnect" href="https://chat.openai.com/" crossorigin="anonymous"><link rel="preload" href="./79_files/3479c143cbeebc46.css" as="style" crossorigin="anonymous"><link rel="stylesheet" href="./79_files/3479c143cbeebc46.css" crossorigin="anonymous" data-n-g=""><noscript data-n-css=""></noscript><script type="text/javascript" async="" src="./79_files/dgkjq2bp"></script><script defer="" crossorigin="anonymous" nomodule="" src="./79_files/polyfills-c67a75d1b6f99dc8.js"></script><script src="./79_files/webpack-836d80a3e891b51c.js" defer="" crossorigin="anonymous"></script><script src="./79_files/framework-31ffa51d236da229.js" defer="" crossorigin="anonymous"></script><script src="./79_files/main-6da2aad3a6c32aae.js" defer="" crossorigin="anonymous"></script><script src="./79_files/_app-5c61b5fdde330fed.js" defer="" crossorigin="anonymous"></script><script src="./79_files/[[...shareParams]]-700bc023a3c41732.js" defer="" crossorigin="anonymous"></script><script src="./79_files/_buildManifest.js" defer="" crossorigin="anonymous"></script><script src="./79_files/_ssgManifest.js" defer="" crossorigin="anonymous"></script><meta name="react-scroll-to-bottom:version" content="4.2.0"><link as="script" rel="prefetch" crossorigin="anonymous" href="./79_files/[gizmoId]-8e1c1bc7b73cf481.js"></head><body class="antialiased"><div id="__next"><script>!function(){try{var d=document.documentElement,c=d.classList;c.remove('light','dark');var e=localStorage.getItem('theme');if('system'===e||(!e&&true)){var t='(prefers-color-scheme: dark)',m=window.matchMedia(t);if(m.media!==t||m.matches){d.style.colorScheme = 'dark';c.add('dark')}else{d.style.colorScheme = 'light';c.add('light')}}else if(e){c.add(e|| '')}if(e==='light'||e==='dark')d.style.colorScheme=e}catch(e){}}()</script><div class="relative z-0 flex h-full w-full overflow-hidden"><div class="relative flex h-full max-w-full flex-1 flex-col overflow-hidden"><main class="relative h-full w-full flex-1 overflow-auto transition-width"><div role="presentation" class="flex h-full flex-col" tabindex="0"><div class="flex-1 overflow-hidden"><div class="h-full overflow-auto bg-token-main-surface-primary"><div class="flex flex-col pb-9 text-sm pt-2"><div class="mx-auto w-full p-4 md:max-w-2xl md:px-0 lg:max-w-[38rem] xl:max-w-3xl"><div class="border-b border-gray-100 pb-4 pt-3 sm:mb-2 sm:pb-6 sm:pt-8"><h1 class="text-3xl font-semibold leading-tight text-token-text-primary sm:text-4xl">Improve Instructor Documentation Page</h1><div class="pt-3 text-base text-gray-400 sm:pt-4">November 15, 2023</div></div></div><div class="w-full text-token-text-primary" data-testid="conversation-turn-2" style="--avatar-color: #19c37d;"><div class="px-4 py-2 justify-center text-base md:gap-6 m-auto"><div class="flex flex-1 text-base mx-auto gap-3 md:max-w-3xl lg:max-w-[40rem] xl:max-w-[48rem] group"><div class="flex-shrink-0 flex flex-col relative items-end"><div><div class="pt-0.5"><div class="gizmo-shadow-stroke flex h-6 w-6 items-center justify-center overflow-hidden rounded-full"><div class="relative p-1 rounded-sm h-9 w-9 text-white flex items-center justify-center" style="background-color: rgb(121, 137, 255); width: 24px; height: 24px;"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="icon-sm" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path><circle cx="12" cy="7" r="4"></circle></svg></div></div></div></div></div><div class="relative flex w-full flex-col"><div class="font-semibold select-none">Anonymous</div><div class="flex-col gap-1 md:gap-3"><div class="flex flex-grow flex-col max-w-full"><div data-message-author-role="user" data-message-id="aaa22b8c-2f45-455a-bce9-25bf72220bf6" class="min-h-[20px] text-message flex flex-col items-start gap-3 whitespace-pre-wrap break-words [.text-message+&amp;]:mt-5 overflow-x-auto"><div class="">improve this page https://jxnl.github.io/instructor/</div></div></div></div></div></div></div></div><div class="w-full text-token-text-primary" data-testid="conversation-turn-3" style="--avatar-color: #19c37d;"><div class="px-4 py-2 justify-center text-base md:gap-6 m-auto"><div class="flex flex-1 text-base mx-auto gap-3 md:max-w-3xl lg:max-w-[40rem] xl:max-w-[48rem] group"><div class="flex-shrink-0 flex flex-col relative items-end"><div><div class="pt-0.5"><div class="gizmo-shadow-stroke flex h-6 w-6 items-center justify-center overflow-hidden rounded-full"><div class="h-6 w-6"><div class="gizmo-shadow-stroke overflow-hidden rounded-full"><img src="./79_files/0d3c6b58-2d37-4f76-887e-5565d3b760fb.png" class="h-full w-full bg-token-main-surface-secondary" alt="GPT" width="80" height="80"></div></div></div></div></div></div><div class="relative flex w-full flex-col agent-turn"><div class="font-semibold select-none">ELIZA</div><div class="flex-col gap-1 md:gap-3"><div class="flex flex-grow flex-col max-w-full"><div data-message-author-role="assistant" data-message-id="a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3" class="min-h-[20px] text-message flex flex-col items-start gap-3 whitespace-pre-wrap break-words [.text-message+&amp;]:mt-5 overflow-x-auto"><div class="markdown prose w-full break-words dark:prose-invert light"><p>The Instructor page you shared is a documentation site for a Python package that facilitates structured data extraction using OpenAI's function calling API. It's designed for simplicity, transparency, and control, and is built specifically to interact with OpenAI's API from Python, aiming to be intuitive and easy to use​<span class="" data-state="closed"><a href="https://jxnl.github.io/instructor/" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19 15" fill="none" class="-mt-0.5 ml-0.5 inline-block text-token-link hover:text-token-link-hover" width="19" height="15"><path d="M4.42 0.75H2.8625H2.75C1.64543 0.75 0.75 1.64543 0.75 2.75V11.65C0.75 12.7546 1.64543 13.65 2.75 13.65H2.8625C2.8625 13.65 2.8625 13.65 2.8625 13.65C2.8625 13.65 4.00751 13.65 4.42 13.65M13.98 13.65H15.5375H15.65C16.7546 13.65 17.65 12.7546 17.65 11.65V2.75C17.65 1.64543 16.7546 0.75 15.65 0.75H15.5375H13.98" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.16045 7.41534C5.32257 7.228 4.69638 6.47988 4.69638 5.58551C4.69638 4.54998 5.53584 3.71051 6.57136 3.71051C7.60689 3.71051 8.44635 4.54998 8.44635 5.58551C8.44635 5.8965 8.37064 6.1898 8.23664 6.448C8.22998 6.48984 8.21889 6.53136 8.20311 6.57208L6.77017 10.2702C6.63182 10.6272 6.18568 10.7873 5.7737 10.6276C5.36172 10.468 5.13991 10.0491 5.27826 9.69206L6.16045 7.41534ZM11.4177 7.41534C10.5798 7.228 9.95362 6.47988 9.95362 5.58551C9.95362 4.54998 10.7931 3.71051 11.8286 3.71051C12.8641 3.71051 13.7036 4.54998 13.7036 5.58551C13.7036 5.8965 13.6279 6.1898 13.4939 6.448C13.4872 6.48984 13.4761 6.53136 13.4604 6.57208L12.0274 10.2702C11.8891 10.6272 11.4429 10.7873 11.0309 10.6276C10.619 10.468 10.3971 10.0491 10.5355 9.69206L11.4177 7.41534Z" fill="currentColor"></path></svg></a></span>​.</p><p>To improve this page, consider the following:</p><ol><li><p><strong>User Experience and Design</strong>: The page layout is straightforward, but it could benefit from a more engaging design. Adding interactive elements, like collapsible sections for different topics, or a search function to quickly find relevant information, would enhance the user experience.</p></li><li><p><strong>Content Clarity</strong>: The current content, such as usage examples​<span class="" data-state="closed"><a href="https://jxnl.github.io/instructor/" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19 15" fill="none" class="-mt-0.5 ml-0.5 inline-block text-token-link hover:text-token-link-hover" width="19" height="15"><path d="M4.42 0.75H2.8625H2.75C1.64543 0.75 0.75 1.64543 0.75 2.75V11.65C0.75 12.7546 1.64543 13.65 2.75 13.65H2.8625C2.8625 13.65 2.8625 13.65 2.8625 13.65C2.8625 13.65 4.00751 13.65 4.42 13.65M13.98 13.65H15.5375H15.65C16.7546 13.65 17.65 12.7546 17.65 11.65V2.75C17.65 1.64543 16.7546 0.75 15.65 0.75H15.5375H13.98" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.16045 7.41534C5.32257 7.228 4.69638 6.47988 4.69638 5.58551C4.69638 4.54998 5.53584 3.71051 6.57136 3.71051C7.60689 3.71051 8.44635 4.54998 8.44635 5.58551C8.44635 5.8965 8.37064 6.1898 8.23664 6.448C8.22998 6.48984 8.21889 6.53136 8.20311 6.57208L6.77017 10.2702C6.63182 10.6272 6.18568 10.7873 5.7737 10.6276C5.36172 10.468 5.13991 10.0491 5.27826 9.69206L6.16045 7.41534ZM11.4177 7.41534C10.5798 7.228 9.95362 6.47988 9.95362 5.58551C9.95362 4.54998 10.7931 3.71051 11.8286 3.71051C12.8641 3.71051 13.7036 4.54998 13.7036 5.58551C13.7036 5.8965 13.6279 6.1898 13.4939 6.448C13.4872 6.48984 13.4761 6.53136 13.4604 6.57208L12.0274 10.2702C11.8891 10.6272 11.4429 10.7873 11.0309 10.6276C10.619 10.468 10.3971 10.0491 10.5355 9.69206L11.4177 7.41534Z" fill="currentColor"></path></svg></a></span>​ and installation instructions​<span class="" data-state="closed"><a href="https://jxnl.github.io/instructor/" target="_blank" rel="noreferrer" class="px-0.5 text-green-600 !no-underline"><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19 15" fill="none" class="-mt-0.5 ml-0.5 inline-block text-token-link hover:text-token-link-hover" width="19" height="15"><path d="M4.42 0.75H2.8625H2.75C1.64543 0.75 0.75 1.64543 0.75 2.75V11.65C0.75 12.7546 1.64543 13.65 2.75 13.65H2.8625C2.8625 13.65 2.8625 13.65 2.8625 13.65C2.8625 13.65 4.00751 13.65 4.42 13.65M13.98 13.65H15.5375H15.65C16.7546 13.65 17.65 12.7546 17.65 11.65V2.75C17.65 1.64543 16.7546 0.75 15.65 0.75H15.5375H13.98" stroke="currentColor" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M6.16045 7.41534C5.32257 7.228 4.69638 6.47988 4.69638 5.58551C4.69638 4.54998 5.53584 3.71051 6.57136 3.71051C7.60689 3.71051 8.44635 4.54998 8.44635 5.58551C8.44635 5.8965 8.37064 6.1898 8.23664 6.448C8.22998 6.48984 8.21889 6.53136 8.20311 6.57208L6.77017 10.2702C6.63182 10.6272 6.18568 10.7873 5.7737 10.6276C5.36172 10.468 5.13991 10.0491 5.27826 9.69206L6.16045 7.41534ZM11.4177 7.41534C10.5798 7.228 9.95362 6.47988 9.95362 5.58551C9.95362 4.54998 10.7931 3.71051 11.8286 3.71051C12.8641 3.71051 13.7036 4.54998 13.7036 5.58551C13.7036 5.8965 13.6279 6.1898 13.4939 6.448C13.4872 6.48984 13.4761 6.53136 13.4604 6.57208L12.0274 10.2702C11.8891 10.6272 11.4429 10.7873 11.0309 10.6276C10.619 10.468 10.3971 10.0491 10.5355 9.69206L11.4177 7.41534Z" fill="currentColor"></path></svg></a></span>​, is clear but could be expanded. More comprehensive examples covering a variety of use cases, detailed explanations of the functions, and potential error handling could make the documentation more robust.</p></li><li><p><strong>Accessibility and Readability</strong>: Ensure that the text is easily readable, with a good contrast between the background and text colors. Using larger fonts and headers can also make the content more accessible.</p></li><li><p><strong>Interactive Code Examples</strong>: Interactive code snippets that users can edit and run directly on the page can be a powerful way to demonstrate the capabilities of the Instructor package.</p></li><li><p><strong>Community Engagement</strong>: Encouraging community contributions through GitHub or a dedicated forum can foster a collaborative environment. Featuring a section for community-contributed tips, tricks, and use cases would be beneficial.</p></li><li><p><strong>SEO Optimization</strong>: To increase the visibility of the page, consider implementing SEO best practices, such as keyword optimization, meta descriptions, and alt text for images.</p></li><li><p><strong>Mobile Responsiveness</strong>: Ensuring the page is fully responsive and looks good on various devices, including tablets and smartphones, is crucial in today's mobile-first world.</p></li><li><p><strong>Feedback Mechanism</strong>: Incorporating a feedback mechanism, like a simple form or comment section, can provide valuable insights from users and help in making continuous improvements.</p></li></ol><p>Remember, the key is to balance technical depth with ease of understanding, making the documentation both informative and approachable for users with different levels of expertise.</p></div></div></div></div></div></div></div></div><div class="w-full text-token-text-primary" data-testid="conversation-turn-4" style="--avatar-color: #19c37d;"><div class="px-4 py-2 justify-center text-base md:gap-6 m-auto"><div class="flex flex-1 text-base mx-auto gap-3 md:max-w-3xl lg:max-w-[40rem] xl:max-w-[48rem] group"><div class="flex-shrink-0 flex flex-col relative items-end"><div><div class="pt-0.5"><div class="gizmo-shadow-stroke flex h-6 w-6 items-center justify-center overflow-hidden rounded-full"><div class="relative p-1 rounded-sm h-9 w-9 text-white flex items-center justify-center" style="background-color: rgb(121, 137, 255); width: 24px; height: 24px;"><svg stroke="currentColor" fill="none" stroke-width="2" viewBox="0 0 24 24" stroke-linecap="round" stroke-linejoin="round" class="icon-sm" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M20 21v-2a4 4 0 0 0-4-4H8a4 4 0 0 0-4 4v2"></path><circle cx="12" cy="7" r="4"></circle></svg></div></div></div></div></div><div class="relative flex w-full flex-col"><div class="font-semibold select-none">Anonymous</div><div class="flex-col gap-1 md:gap-3"><div class="flex flex-grow flex-col max-w-full"><div data-message-author-role="user" data-message-id="aaa21873-cfb5-42e1-ab3e-d81b714f99ce" class="min-h-[20px] text-message flex flex-col items-start gap-3 whitespace-pre-wrap break-words [.text-message+&amp;]:mt-5 overflow-x-auto"><div class="">give me a sample of the prose rewritten</div></div></div></div></div></div></div></div><div class="w-full text-token-text-primary" data-testid="conversation-turn-5" style="--avatar-color: #19c37d;"><div class="px-4 py-2 justify-center text-base md:gap-6 m-auto"><div class="flex flex-1 text-base mx-auto gap-3 md:max-w-3xl lg:max-w-[40rem] xl:max-w-[48rem] group final-completion"><div class="flex-shrink-0 flex flex-col relative items-end"><div><div class="pt-0.5"><div class="gizmo-shadow-stroke flex h-6 w-6 items-center justify-center overflow-hidden rounded-full"><div class="h-6 w-6"><div class="gizmo-shadow-stroke overflow-hidden rounded-full"><img src="./79_files/0d3c6b58-2d37-4f76-887e-5565d3b760fb.png" class="h-full w-full bg-token-main-surface-secondary" alt="GPT" width="80" height="80"></div></div></div></div></div></div><div class="relative flex w-full flex-col agent-turn"><div class="font-semibold select-none">ELIZA</div><div class="flex-col gap-1 md:gap-3"><div class="flex flex-grow flex-col max-w-full"><div data-message-author-role="assistant" data-message-id="cbcf902d-5adc-4bc0-bdf2-996da301ad65" class="min-h-[20px] text-message flex flex-col items-start gap-3 whitespace-pre-wrap break-words [.text-message+&amp;]:mt-5 overflow-x-auto"><div class="markdown prose w-full break-words dark:prose-invert light"><p>Certainly! Here's a rewritten sample of the prose for the Instructor page, focusing on user-friendliness and clarity:</p><hr><p><strong>Welcome to Instructor - Your Gateway to Streamlined Data Extraction with OpenAI</strong></p><p>Dive into the world of Python-based structured extraction, empowered by OpenAI's cutting-edge function calling API. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you're a seasoned developer or just starting out, you'll find Instructor's approach intuitive and its results insightful.</p><p><strong>Get Started in Moments</strong></p><p>Installing Instructor is a breeze. Just run <code>pip install instructor</code> in your terminal and you're on your way to a smoother data handling experience.</p><p><strong>How Instructor Enhances Your Workflow</strong></p><p>Our patch for the <code>ChatCompletion</code> class introduces three key enhancements:</p><ol><li><strong>Response Model</strong>: Specify a Pydantic model to streamline data extraction.</li><li><strong>Max Retries</strong>: Set your desired number of retry attempts for requests.</li><li><strong>Validation Context</strong>: Provide a context object for enhanced validator access.</li></ol><p><strong>A Glimpse into Instructor's Capabilities</strong></p><p>With Instructor, your code becomes more efficient and readable. Here’s a quick peek:</p><pre><div class="dark bg-gray-950 rounded-md"><div class="flex items-center relative text-token-text-secondary bg-token-main-surface-secondary px-4 py-2 text-xs font-sans justify-between rounded-t-md"><span>python</span><span class="" data-state="closed"><button class="flex gap-1 items-center"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg" class="icon-sm"><path fill-rule="evenodd" clip-rule="evenodd" d="M12 4C10.8954 4 10 4.89543 10 6H14C14 4.89543 13.1046 4 12 4ZM8.53513 4C9.22675 2.8044 10.5194 2 12 2C13.4806 2 14.7733 2.8044 15.4649 4H17C18.6569 4 20 5.34315 20 7V19C20 20.6569 18.6569 22 17 22H7C5.34315 22 4 20.6569 4 19V7C4 5.34315 5.34315 4 7 4H8.53513ZM8 6H7C6.44772 6 6 6.44772 6 7V19C6 19.5523 6.44772 20 7 20H17C17.5523 20 18 19.5523 18 19V7C18 6.44772 17.5523 6 17 6H16C16 7.10457 15.1046 8 14 8H10C8.89543 8 8 7.10457 8 6Z" fill="currentColor"></path></svg>Copy code</button></span></div><div class="p-4 overflow-y-auto"><code class="!whitespace-pre hljs language-python"><span class="hljs-keyword">from</span> openai <span class="hljs-keyword">import</span> OpenAI
<span class="hljs-keyword">import</span> instructor

client = instructor.patch(OpenAI())

<span class="hljs-comment"># Define a user detail model</span>
<span class="hljs-keyword">class</span> <span class="hljs-title class_">UserDetail</span>(<span class="hljs-title class_ inherited__">BaseModel</span>):
    name: <span class="hljs-built_in">str</span>
    age: <span class="hljs-built_in">int</span>

<span class="hljs-comment"># Extract user details with ease</span>
user = client.chat.completions.create(
    model=<span class="hljs-string">"gpt-3.5-turbo"</span>,
    response_model=UserDetail,
    messages=[{<span class="hljs-string">"role"</span>: <span class="hljs-string">"user"</span>, <span class="hljs-string">"content"</span>: <span class="hljs-string">"Extract Jason is 25 years old"</span>}]
)

<span class="hljs-keyword">assert</span> <span class="hljs-built_in">isinstance</span>(user, UserDetail)
<span class="hljs-keyword">assert</span> user.name == <span class="hljs-string">"Jason"</span>
<span class="hljs-keyword">assert</span> user.age == <span class="hljs-number">25</span>
</code></div></div></pre><p><strong>Engage, Explore, Excel</strong></p><p>Your journey with Instructor doesn't end with code. Join our GitHub community, share your experiences, and grow with fellow enthusiasts. Together, let's redefine the possibilities of Python and OpenAI.</p><hr><p>This revised version focuses on making the information more engaging and easier to digest, with clear section headers and an inviting tone.</p></div></div></div></div></div></div></div></div></div></div></div><div class="w-full pt-2 md:pt-0 dark:border-white/20 md:border-transparent md:dark:border-transparent md:w-[calc(100%-.5rem)]"><div class="relative flex w-full flex-1 items-center justify-center gap-2 pt-3 empty:hidden"><a class="flex items-center gap-2 rounded-xl bg-green-600 px-5 py-3.5 font-medium text-white transition hover:opacity-70 w-40 justify-center" href="https://chat.openai.com/g/g-8iui73B2J-eliza"><div>Upgrade to Plus to chat with <span class="font-bold">ELIZA</span></div></a></div><div class="relative px-2 py-2 text-center text-xs text-token-text-secondary md:px-[60px]"><div class="flex justify-center gap-3 text-token-text-tertiary"><button>Report content</button><span>|</span><a href="https://openai.com/policies/terms-of-use" target="_blank" rel="noreferrer">Terms of use</a><span>|</span><a href="https://openai.com/policies/privacy-policy" target="_blank" rel="noreferrer">Privacy policy</a><span>|</span></div></div></div></div><div class="group fixed bottom-3 right-3 z-10 hidden gap-1 lg:flex"><div class="group relative" data-headlessui-state=""><button class="flex items-center justify-center rounded-full border border-token-border-light text-token-text-secondary" id="headlessui-menu-button-:r4:" type="button" aria-haspopup="true" aria-expanded="false" data-headlessui-state=""><div class="flex h-6 w-6 items-center justify-center text-xs">?</div></button></div></div></main></div></div><div class="absolute left-0 right-0 top-0 z-[2]"></div></div><script id="__NEXT_DATA__" type="application/json" crossorigin="anonymous">{"props":{"pageProps":{"serverPrimedAllowBrowserStorageValue":true,"isStorageComplianceEnabled":false,"user":{"id":"user-DiQTGiGVFqze6dprFzmFn9HU","name":"Daniel Ogenrwot","email":"ogenrwot@unlv.nevada.edu","image":"https://lh3.googleusercontent.com/a/ACg8ocJs3eXuKK9Cvxw--rhfLSyMa7t75KLFfn8RZjuspp7ofw=s96-c","picture":"https://lh3.googleusercontent.com/a/ACg8ocJs3eXuKK9Cvxw--rhfLSyMa7t75KLFfn8RZjuspp7ofw=s96-c","idp":"google-oauth2","iat":1704763431,"mfa":false,"groups":[],"intercom_hash":"b1696c9b7c3e106e5e1562cebe511d91a2b7ecaada4affd27e426cd79ce86e2f"},"serviceStatus":{},"serviceAnnouncement":{"public":{},"paid":{}},"cfConnectingIp":"2600:8801:359a:b200:10b1:c381:2196:e960","statsig":{"payload":{"feature_gates":{"mC7arE5IsSMGuGv+JtQNn6PkLNjGMgnPGm4lNwCVcd4=":{"name":"mC7arE5IsSMGuGv+JtQNn6PkLNjGMgnPGm4lNwCVcd4=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:chatgpt_voice_team","gateValue":"false","ruleID":"default"}]},"4bxrZiqrvUhz7pNmrq7/hje8GGth3CK38a+UCoGT55w=":{"name":"4bxrZiqrvUhz7pNmrq7/hje8GGth3CK38a+UCoGT55w=","value":false,"rule_id":"6Usmt3Th0mkUkVQJ0oyeST:0.00:1","secondary_exposures":[]},"BwgqaCydMQQ3DfMuT3le70YG2UMR90ZQUizkz8s87Og=":{"name":"BwgqaCydMQQ3DfMuT3le70YG2UMR90ZQUizkz8s87Og=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:chatgpt_voice_team","gateValue":"false","ruleID":"default"}]},"sB09rxeNC0dm+q105n4ilqzJPvZ+fb8Adgn7dgHyAJs=":{"name":"sB09rxeNC0dm+q105n4ilqzJPvZ+fb8Adgn7dgHyAJs=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:chatgpt_voice_team","gateValue":"false","ruleID":"default"}]},"/sqBSo8CbSfm33mGuPq/xK+GiRwPnbT26mPKmQkikn4=":{"name":"/sqBSo8CbSfm33mGuPq/xK+GiRwPnbT26mPKmQkikn4=","value":false,"rule_id":"default","secondary_exposures":[]},"8YdWfy6BaXA6MDnlnTc17AwNRhxQ4rcfy5G+sYaHQ/A=":{"name":"8YdWfy6BaXA6MDnlnTc17AwNRhxQ4rcfy5G+sYaHQ/A=","value":false,"rule_id":"63qNN95X7P6VSHVff2nL76","secondary_exposures":[]},"9frMP2Uapo9+GZFF/eyDv3qypmVGR3bBx7kQxlUjFL0=":{"name":"9frMP2Uapo9+GZFF/eyDv3qypmVGR3bBx7kQxlUjFL0=","value":false,"rule_id":"4Cs7bnD6u8s4FIa2CdgJ7i","secondary_exposures":[]},"zP79mMrzyNTmUIk4BvnRSRf1QyskcWqpVbgx/DuBSlk=":{"name":"zP79mMrzyNTmUIk4BvnRSRf1QyskcWqpVbgx/DuBSlk=","value":false,"rule_id":"default","secondary_exposures":[]},"G4FKkwqOMLlLXCjFizXkc6Fbyds7IQgmeDgcOnlzXcc=":{"name":"G4FKkwqOMLlLXCjFizXkc6Fbyds7IQgmeDgcOnlzXcc=","value":false,"rule_id":"default","secondary_exposures":[]},"Ot01tCFiILXHbMzQliq1LFtcH9p484nys9JQ3jNBBSc=":{"name":"Ot01tCFiILXHbMzQliq1LFtcH9p484nys9JQ3jNBBSc=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:european_legal_restricted","gateValue":"false","ruleID":"default"}]},"ZB1N+sYIfld1iUD73LMNp+7PHtb5fjkv1Fqd9stCmhM=":{"name":"ZB1N+sYIfld1iUD73LMNp+7PHtb5fjkv1Fqd9stCmhM=","value":false,"rule_id":"default","secondary_exposures":[]},"AmHQM8fzcDgvtrUTWfKdHeeC+liSx6Ap3mIjS2v2T7k=":{"name":"AmHQM8fzcDgvtrUTWfKdHeeC+liSx6Ap3mIjS2v2T7k=","value":false,"rule_id":"1IdfApkb0f3RHjOg804mYI:5.00:5","secondary_exposures":[]},"v6yV8GS0zH+VdEey3WZ8OCkuXSPit1tWZ1w5XGJKgwU=":{"name":"v6yV8GS0zH+VdEey3WZ8OCkuXSPit1tWZ1w5XGJKgwU=","value":true,"rule_id":"VNBdYfNSNNUyDdMpaiaZ9:100.00:1","secondary_exposures":[]},"bZIChv8u2y59nAdcmf3Sxu+c4LOtTeRmbLn99GUUOrQ=":{"name":"bZIChv8u2y59nAdcmf3Sxu+c4LOtTeRmbLn99GUUOrQ=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:gizmo_store_team","gateValue":"false","ruleID":"default"},{"gate":"segment:memory_team","gateValue":"false","ruleID":"default"}]},"NFLu/8gcH3+m9yHiY/kPxE83zLFYMhk3cWVEq2zR+NM=":{"name":"NFLu/8gcH3+m9yHiY/kPxE83zLFYMhk3cWVEq2zR+NM=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"XrhPGbeUzfIBQaHMWl4/GYZzdDnDMzHb96RYes5lw2w=":{"name":"XrhPGbeUzfIBQaHMWl4/GYZzdDnDMzHb96RYes5lw2w=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"FEo7XK0f7Hn3U2RwSds2DTiEYNIpKCqrSVA2UP0BK2M=":{"name":"FEo7XK0f7Hn3U2RwSds2DTiEYNIpKCqrSVA2UP0BK2M=","value":true,"rule_id":"6sEu91zwlBGSKOqFiNpGlA:100.00:2","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"},{"gate":"segment:enterprise","gateValue":"false","ruleID":"default"},{"gate":"segment:teams_plan","gateValue":"false","ruleID":"default"}]},"9WcM78XE5AQPxf3Yv9FxM5g14rV2Sk3HsGRha1mAnxc=":{"name":"9WcM78XE5AQPxf3Yv9FxM5g14rV2Sk3HsGRha1mAnxc=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"+ZnfGOKTXqj/PUluVHtQHH4xXcWomraW0OeynJkthMA=":{"name":"+ZnfGOKTXqj/PUluVHtQHH4xXcWomraW0OeynJkthMA=","value":true,"rule_id":"2LpyNTIfbYC4R6XS6dfdIL","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"a2qAmsyD94P0/7pZ6SpRYRKL9Odkp+5z2KgEZEYvsJg=":{"name":"a2qAmsyD94P0/7pZ6SpRYRKL9Odkp+5z2KgEZEYvsJg=","value":false,"rule_id":"default","secondary_exposures":[]}},"dynamic_configs":{"krxquX5lr9NsWYuE6AxcgDMKBdc3hX7WV56L3qm2h+k=":{"name":"krxquX5lr9NsWYuE6AxcgDMKBdc3hX7WV56L3qm2h+k=","value":{},"group":"default","rule_id":"default","is_device_based":false,"secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"},{"gate":"chatgpt-browse-sahara","gateValue":"false","ruleID":"default"}]},"Xxhhbjq3NEImgVIfGzx+Ubl6ebJS1kwRjV/2YlHJ3Zs=":{"name":"Xxhhbjq3NEImgVIfGzx+Ubl6ebJS1kwRjV/2YlHJ3Zs=","value":{"google.com":["google.com","googleapis.com","www.googleapis.com","oauth2.googleapis.com"],"microsoftonline.com":["microsoft.com","microsoftonline.com"],"adobelogin.com":["adobe.com","adobelogin.com"],"useflorian.com":["useflorian.com","convex.site"],"yahoo.com":["yahooapis.com","yahoo.com"],"app.vssps.visualstudio.com":["app.vssps.visualstudio.com","dev.azure.com"]},"group":"default","rule_id":"default","is_device_based":true,"secondary_exposures":[]},"LH4aXUWdAthHnhoeezgqr9XUAj+EyFN9/INZTPgB8Rw=":{"name":"LH4aXUWdAthHnhoeezgqr9XUAj+EyFN9/INZTPgB8Rw=","value":{},"group":"prestart","rule_id":"prestart","is_device_based":false,"secondary_exposures":[],"is_user_in_experiment":false,"is_experiment_active":false},"/NA6RKoyvTPtJS+65jbxYPRbn4zCKaPi28t+RGlIi74=":{"name":"/NA6RKoyvTPtJS+65jbxYPRbn4zCKaPi28t+RGlIi74=","value":{},"group":"prestart","rule_id":"prestart","is_device_based":false,"secondary_exposures":[],"is_user_in_experiment":false,"is_experiment_active":false},"d88zqiv5tj+jTJIQj6D5/mZRDEaFP6YEIqcwlz6Nh+8=":{"name":"d88zqiv5tj+jTJIQj6D5/mZRDEaFP6YEIqcwlz6Nh+8=","value":{},"group":"targetingGate","rule_id":"targetingGate","is_device_based":false,"secondary_exposures":[{"gate":"targeting-aa-web-240206","gateValue":"false","ruleID":"63qNN95X7P6VSHVff2nL76"}],"is_user_in_experiment":false,"is_experiment_active":true},"hxxW3hikZ7rigchg97AizJTpHbpMCwkwvbZd7t9sblc=":{"name":"hxxW3hikZ7rigchg97AizJTpHbpMCwkwvbZd7t9sblc=","value":{},"group":"targetingGate","rule_id":"targetingGate","is_device_based":false,"secondary_exposures":[{"gate":"targeting-aa-web-anon-240206","gateValue":"false","ruleID":"4Cs7bnD6u8s4FIa2CdgJ7i"}],"is_user_in_experiment":false,"is_experiment_active":true},"2gcgWHw6EUQ7WzuausBVbg88/jglfC1LmtqhBF35u2c=":{"name":"2gcgWHw6EUQ7WzuausBVbg88/jglfC1LmtqhBF35u2c=","value":{"show_new_ui":true},"group":"launchedGroup","rule_id":"launchedGroup","is_device_based":false,"secondary_exposures":[],"is_user_in_experiment":false,"is_experiment_active":false}},"layer_configs":{},"sdkParams":{},"has_updates":true,"generator":"statsig-node-sdk","time":0,"evaluated_keys":{"userID":"user-DiQTGiGVFqze6dprFzmFn9HU","customIDs":{"WebAnonymousCookieID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","DeviceId":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","stableID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093"}},"hash_used":"sha256","user_hash":"2623322862"},"user":{"country":"US","custom":{"auth_status":"logged_in","is_paid":false},"customIDs":{"WebAnonymousCookieID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","DeviceId":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","stableID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093"},"ip":"2600:8801:359a:b200:10b1:c381:2196:e960","locale":"en-US","privateAttributes":{"email":"ogenrwot@unlv.nevada.edu"},"userAgent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36","userID":"user-DiQTGiGVFqze6dprFzmFn9HU"}},"showCookieConsentBanner":false,"ageVerificationDeadline":null,"ageVerificationType":"none","logOutUser":false,"sharedConversationId":"51b5e459-6956-4591-b8a9-beeae0401063","serverResponse":{"type":"data","data":{"title":"Improve Instructor Documentation Page","create_time":1700092220.469242,"update_time":1700092260,"mapping":{"cbcf902d-5adc-4bc0-bdf2-996da301ad65":{"id":"cbcf902d-5adc-4bc0-bdf2-996da301ad65","message":{"id":"cbcf902d-5adc-4bc0-bdf2-996da301ad65","author":{"role":"assistant","metadata":{}},"create_time":1700092162.250364,"content":{"content_type":"text","parts":["Certainly! Here's a rewritten sample of the prose for the Instructor page, focusing on user-friendliness and clarity:\n\n---\n\n**Welcome to Instructor - Your Gateway to Streamlined Data Extraction with OpenAI**\n\nDive into the world of Python-based structured extraction, empowered by OpenAI's cutting-edge function calling API. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you're a seasoned developer or just starting out, you'll find Instructor's approach intuitive and its results insightful.\n\n**Get Started in Moments**\n\nInstalling Instructor is a breeze. Just run `pip install instructor` in your terminal and you're on your way to a smoother data handling experience.\n\n**How Instructor Enhances Your Workflow**\n\nOur patch for the `ChatCompletion` class introduces three key enhancements:\n\n1. **Response Model**: Specify a Pydantic model to streamline data extraction.\n2. **Max Retries**: Set your desired number of retry attempts for requests.\n3. **Validation Context**: Provide a context object for enhanced validator access.\n\n**A Glimpse into Instructor's Capabilities**\n\nWith Instructor, your code becomes more efficient and readable. Here’s a quick peek:\n\n```python\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.patch(OpenAI())\n\n# Define a user detail model\nclass UserDetail(BaseModel):\n    name: str\n    age: int\n\n# Extract user details with ease\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=UserDetail,\n    messages=[{\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"}]\n)\n\nassert isinstance(user, UserDetail)\nassert user.name == \"Jason\"\nassert user.age == 25\n```\n\n**Engage, Explore, Excel**\n\nYour journey with Instructor doesn't end with code. Join our GitHub community, share your experiences, and grow with fellow enthusiasts. Together, let's redefine the possibilities of Python and OpenAI.\n\n---\n\nThis revised version focuses on making the information more engaging and easier to digest, with clear section headers and an inviting tone."]},"status":"finished_successfully","end_turn":true,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100260]},"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","children":[]},"aaa21873-cfb5-42e1-ab3e-d81b714f99ce":{"id":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","message":{"id":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","author":{"role":"user","metadata":{}},"create_time":1700092123.736646,"content":{"content_type":"text","parts":["give me a sample of the prose rewritten"]},"status":"finished_successfully","weight":1,"metadata":{"timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3","children":["cbcf902d-5adc-4bc0-bdf2-996da301ad65"]},"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3":{"id":"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3","message":{"id":"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3","author":{"role":"assistant","metadata":{}},"create_time":1700092075.083032,"content":{"content_type":"text","parts":["The Instructor page you shared is a documentation site for a Python package that facilitates structured data extraction using OpenAI's function calling API. It's designed for simplicity, transparency, and control, and is built specifically to interact with OpenAI's API from Python, aiming to be intuitive and easy to use【7†source】.\n\nTo improve this page, consider the following:\n\n1. **User Experience and Design**: The page layout is straightforward, but it could benefit from a more engaging design. Adding interactive elements, like collapsible sections for different topics, or a search function to quickly find relevant information, would enhance the user experience.\n\n2. **Content Clarity**: The current content, such as usage examples【8†source】 and installation instructions【9†source】, is clear but could be expanded. More comprehensive examples covering a variety of use cases, detailed explanations of the functions, and potential error handling could make the documentation more robust.\n\n3. **Accessibility and Readability**: Ensure that the text is easily readable, with a good contrast between the background and text colors. Using larger fonts and headers can also make the content more accessible.\n\n4. **Interactive Code Examples**: Interactive code snippets that users can edit and run directly on the page can be a powerful way to demonstrate the capabilities of the Instructor package.\n\n5. **Community Engagement**: Encouraging community contributions through GitHub or a dedicated forum can foster a collaborative environment. Featuring a section for community-contributed tips, tricks, and use cases would be beneficial.\n\n6. **SEO Optimization**: To increase the visibility of the page, consider implementing SEO best practices, such as keyword optimization, meta descriptions, and alt text for images.\n\n7. **Mobile Responsiveness**: Ensuring the page is fully responsive and looks good on various devices, including tablets and smartphones, is crucial in today's mobile-first world.\n\n8. **Feedback Mechanism**: Incorporating a feedback mechanism, like a simple form or comment section, can provide valuable insights from users and help in making continuous improvements.\n\nRemember, the key is to balance technical depth with ease of understanding, making the documentation both informative and approachable for users with different levels of expertise."]},"status":"finished_successfully","end_turn":true,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100260]},"citations":[{"start_ix":321,"end_ix":331,"citation_format_type":"tether_og","metadata":{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"# Getting Started with Instructor【0†¶】\n\nStructured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\n\n* * *\n\n【40†Star us on Github!】.\n\n[Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\n\nBuilt to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.","extra":{"cited_message_idx":7,"evidence_text":"source"}}},{"start_ix":741,"end_ix":751,"citation_format_type":"tether_og","metadata":{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Usage【29†¶】\n\n    from openai import OpenAI\n    import instructor\n\n    # Enables `response_model`\n    client = instructor.patch(OpenAI())\n\n    class UserDetail(BaseModel):\n        name: str\n        age: int\n\n    user = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n        ]\n    )\n\n    assert isinstance(user, UserDetail)\n    assert user.name == \"Jason\"\n    assert user.age == 25","extra":{"cited_message_idx":8,"evidence_text":"source"}}},{"start_ix":781,"end_ix":791,"citation_format_type":"tether_og","metadata":{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Installation【30†¶】\n\nTo get started you need to install it using `pip`. Run the following command in your terminal:\n\n    $ pip install instructor\n\n## Quick Start【31†¶】\n\nTo simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\n\n  1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\n  2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\n  3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.","extra":{"cited_message_idx":9,"evidence_text":"source"}}}],"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"fbf0a063-f51c-4570-89db-be2b180d6887","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"fbf0a063-f51c-4570-89db-be2b180d6887","children":["aaa21873-cfb5-42e1-ab3e-d81b714f99ce"]},"fbf0a063-f51c-4570-89db-be2b180d6887":{"id":"fbf0a063-f51c-4570-89db-be2b180d6887","message":{"id":"fbf0a063-f51c-4570-89db-be2b180d6887","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.079015,"content":{"content_type":"tether_quote","url":"https://jxnl.github.io/instructor/","domain":"jxnl.github.io","text":"## Installation【30†¶】\n\nTo get started you need to install it using `pip`. Run the following command in your terminal:\n\n    $ pip install instructor\n\n## Quick Start【31†¶】\n\nTo simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\n\n  1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\n  2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\n  3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.","title":"Quick Start - Instructor (openai_function_call)"},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Installation【30†¶】\n\nTo get started you need to install it using `pip`. Run the following command in your terminal:\n\n    $ pip install instructor\n\n## Quick Start【31†¶】\n\nTo simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\n\n  1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\n  2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\n  3. The `validation_context` parameter, which allows you to specify a context object that validators have access to."}]},"command":"quote_lines","args":[160,172],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","children":["a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3"]},"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d":{"id":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","message":{"id":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.074878,"content":{"content_type":"tether_quote","url":"https://jxnl.github.io/instructor/","domain":"jxnl.github.io","text":"## Usage【29†¶】\n\n    from openai import OpenAI\n    import instructor\n\n    # Enables `response_model`\n    client = instructor.patch(OpenAI())\n\n    class UserDetail(BaseModel):\n        name: str\n        age: int\n\n    user = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n        ]\n    )\n\n    assert isinstance(user, UserDetail)\n    assert user.name == \"Jason\"\n    assert user.age == 25","title":"Quick Start - Instructor (openai_function_call)"},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Usage【29†¶】\n\n    from openai import OpenAI\n    import instructor\n\n    # Enables `response_model`\n    client = instructor.patch(OpenAI())\n\n    class UserDetail(BaseModel):\n        name: str\n        age: int\n\n    user = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n        ]\n    )\n\n    assert isinstance(user, UserDetail)\n    assert user.name == \"Jason\"\n    assert user.age == 25"}]},"command":"quote_lines","args":[99,121],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"084094e7-e16a-45dd-a583-e750645fb844","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"084094e7-e16a-45dd-a583-e750645fb844","children":["fbf0a063-f51c-4570-89db-be2b180d6887"]},"084094e7-e16a-45dd-a583-e750645fb844":{"id":"084094e7-e16a-45dd-a583-e750645fb844","message":{"id":"084094e7-e16a-45dd-a583-e750645fb844","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.070938,"content":{"content_type":"tether_quote","url":"https://jxnl.github.io/instructor/","domain":"jxnl.github.io","text":"# Getting Started with Instructor【0†¶】\n\nStructured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\n\n* * *\n\n【40†Star us on Github!】.\n\n[Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\n\nBuilt to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.","title":"Quick Start - Instructor (openai_function_call)"},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"# Getting Started with Instructor【0†¶】\n\nStructured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\n\n* * *\n\n【40†Star us on Github!】.\n\n[Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\n\nBuilt to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts."}]},"command":"quote_lines","args":[87,97],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"06727e48-6085-4ff8-8ac2-890d2041f492","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"06727e48-6085-4ff8-8ac2-890d2041f492","children":["b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d"]},"06727e48-6085-4ff8-8ac2-890d2041f492":{"id":"06727e48-6085-4ff8-8ac2-890d2041f492","message":{"id":"06727e48-6085-4ff8-8ac2-890d2041f492","author":{"role":"assistant","metadata":{}},"create_time":1700092075.065864,"content":{"content_type":"code","language":"unknown","text":"quote_lines(87, 97);\nquote_lines(99, 121);\nquote_lines(160, 172);"},"status":"finished_successfully","end_turn":false,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100265]},"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"4557cc9e-fef2-4ab0-8369-67ab695beaea","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"browser"},"parent":"4557cc9e-fef2-4ab0-8369-67ab695beaea","children":["084094e7-e16a-45dd-a583-e750645fb844"]},"4557cc9e-fef2-4ab0-8369-67ab695beaea":{"id":"4557cc9e-fef2-4ab0-8369-67ab695beaea","message":{"id":"4557cc9e-fef2-4ab0-8369-67ab695beaea","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.061035,"content":{"content_type":"tether_browsing_display","result":"L0: \nL1: URL: https://jxnl.github.io/instructor/\nL2:  \nL3: \nL4: 【0† Skip to content 】 \nL5: \nL6: 【1† 】 \nL7: \nL8: Instructor (openai_function_call) \nL9: \nL10: Quick Start \nL11: \nL12:   【2† †javascript:void(0)】 \nL13: \nL14: Initializing search \nL15: \nL16: 【3† instructor †github.com】 \nL17: \nL18:   * 【1† Introduction 】 \nL19:   * 【4† Cookbook 】 \nL20:   * 【5† CLI Reference 】 \nL21:   * 【6† API Reference 】 \nL22:   * 【7† Blog 】 \nL23: \nL24: 【1† 】 Instructor (openai_function_call) \nL25: \nL26: 【3† instructor †github.com】 \nL27: \nL28:   * \nL29: \nL30: 【1† Introduction 】  \nL31: \nL32: Introduction \nL33:     * 【8† Validators 】 \nL34:     * 【9† Distillation 】 \nL35:     * 【10† Prompt Engineering Tips 】 \nL36:     * 【11† Philosophy 】 \nL37:   * \nL38: \nL39: 【4† Cookbook 】  \nL40: \nL41: Cookbook \nL42:     * 【12† Streaming Lists 】 \nL43:     * 【13† Handling Missing Content 】 \nL44:     * 【14† Text Classification 】 \nL45:     * 【15† Self Critique 】 \nL46:     * 【16† Citations 】 \nL47:     * 【17† Knowledge Graph 】 \nL48:     * 【18† Entity Resolution 】 \nL49:     * 【19† Search Queries 】 \nL50:     * 【20† Query Decomposition 】 \nL51:     * 【21† Recursive Schemas 】 \nL52:     * 【22† Table Extraction 】 \nL53:     * 【23† Action Item and Dependency Mapping 】 \nL54:     * 【24† Multi-File Code Generation 】 \nL55:     * 【25† PII Data Sanitization 】 \nL56:   * \nL57: \nL58: 【5† CLI Reference 】  \nL59: \nL60: CLI Reference \nL61:     * 【26† Finetuning GPT-3.5 】 \nL62:     * 【27† Usage Tracking 】 \nL63:   *    API Reference  API Reference \nL64:     * 【6† Core Library 】 \nL65:   * \nL66: \nL67: 【7† Blog 】  \nL68: \nL69: Blog \nL70:     *    Archive  Archive \nL71:       * 【28† 2023 】 \nL72: \nL73: Table of contents \nL74: \nL75:   * 【29† Usage 】 \nL76:   * 【30† Installation 】 \nL77:   * 【31† Quick Start 】 \nL78:     * 【32† Step 1: Patch the client 】 \nL79:     * 【33† Step 2: Define the Pydantic Model 】 \nL80:     * 【34† Step 3: Extract 】 \nL81:   * 【35† Pydantic Validation 】 \nL82:   * 【36† Reask on validation error 】 \nL83:   * 【37† License 】 \nL84: \nL85: 【38† †github.com】 【39† †github.com】 \nL86: \nL87: # Getting Started with Instructor【0†¶】\nL88: \nL89: Structured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\nL90: \nL91: * * *\nL92: \nL93: 【40†Star us on Github!】.\nL94: \nL95: [Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\nL96: \nL97: Built to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.\nL98: \nL99: ## Usage【29†¶】\nL100: \nL101:     from openai import OpenAI\nL102:     import instructor\nL103: \nL104:     # Enables `response_model`\nL105:     client = instructor.patch(OpenAI())\nL106: \nL107:     class UserDetail(BaseModel):\nL108:         name: str\nL109:         age: int\nL110: \nL111:     user = client.chat.completions.create(\nL112:         model=\"gpt-3.5-turbo\",\nL113:         response_model=UserDetail,\nL114:         messages=[\nL115:             {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\nL116:         ]\nL117:     )\nL118: \nL119:     assert isinstance(user, UserDetail)\nL120:     assert user.name == \"Jason\"\nL121:     assert user.age == 25\nL122: \nL123: Using `openai\u003c1.0.0`\nL124: \nL125: If you're using `openai\u003c1.0.0` then make sure you `pip install instructor\u003c0.3.0` where you can patch a global client like so:\nL126: \nL127:     import openai\nL128:     import instructor\nL129: \nL130:     instructor.patch()\nL131: \nL132:     user = openai.ChatCompletion.create(\nL133:         ...,\nL134:         response_model=UserDetail,\nL135:     )\nL136: \nL137: Using async clients\nL138: \nL139: For async clients you must use apatch vs patch like so:\nL140: \nL141:     import instructor\nL142:     from openai import AsyncOpenAI\nL143: \nL144:     aclient = instructor.apatch(AsyncOpenAI())\nL145: \nL146:     class UserExtract(BaseModel):\nL147:         name: str\nL148:         age: int\nL149: \nL150:     model = await aclient.chat.completions.create(\nL151:         model=\"gpt-3.5-turbo\",\nL152:         response_model=UserExtract,\nL153:         messages=[\nL154:             {\"role\": \"user\", \"content\": \"Extract jason is 25 years old\"},\nL155:         ],\nL156:     )\nL157: \nL158:     assert isinstance(model, UserExtract)\nL159: \nL160: ## Installation【30†¶】\nL161: \nL162: To get started you need to install it using `pip`. Run the following command in your terminal:\nL163: \nL164:     $ pip install instructor\nL165: \nL166: ## Quick Start【31†¶】\nL167: \nL168: To simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\nL169: \nL170:   1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\nL171:   2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\nL172:   3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.\nL173: \nL174: Using Validators\nL175: \nL176: Learn more about validators checkout our blog post 【41†Good llm validation is just good validation】\nL177: \nL178: ### Step 1: Patch the client【32†¶】\nL179: \nL180: First, import the required libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter.\nL181: \nL182:     import instructor\nL183:     from openai import OpenAI\nL184:     from pydantic import BaseModel\nL185: \nL186:     # This enables response_model keyword\nL187:     # from client.chat.completions.create\nL188:     client = instructor.patch(OpenAI())\nL189: \nL190: ### Step 2: Define the Pydantic Model【33†¶】\nL191: \nL192: Create a Pydantic model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.\nL193: \nL194:     from pydantic import BaseModel\nL195: \nL196:     class UserDetail(BaseModel):\nL197:         name: str\nL198:         age: int\nL199: \nL200: ### Step 3: Extract【34†¶】\nL201\nVisible: 0% - 64%","summary":"Quick Start - Instructor (openai_function_call) (jxnl.github.io)\n","assets":[]},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"L0: \nL1: URL: https://jxnl.github.io/instructor/\nL2:  \nL3: \nL4:  Skip to content  \nL5: \nL6:   \nL7: \nL8: Instructor (openai_function_call) \nL9: \nL10: Quick Start \nL11: \nL12:     \nL13: \nL14: Initializing search \nL15: \nL16:  instructor  \nL17: \nL18:   *  Introduction  \nL19:   *  Cookbook  \nL20:   *  CLI Reference  \nL21:   *  API Reference  \nL22:   *  Blog  \nL23: \nL24:   Instructor (openai_function_call) \nL25: \nL26:  instructor  \nL27: \nL28:   * \nL29: \nL30:  Introduction   \nL31: \nL32: Introduction \nL33:     *  Validators  \nL34:     *  Distillation  \nL35:     *  Prompt Engineering Tips  \nL36:     *  Philosophy  \nL37:   * \nL38: \nL39:  Cookbook   \nL40: \nL41: Cookbook \nL42:     *  Streaming Lists  \nL43:     *  Handling Missing Content  \nL44:     *  Text Classification  \nL45:     *  Self Critique  \nL46:     *  Citations  \nL47:     *  Knowledge Graph  \nL48:     *  Entity Resolution  \nL49:     *  Search Queries  \nL50:     *  Query Decomposition  \nL51:     *  Recursive Schemas  \nL52:     *  Table Extraction  \nL53:     *  Action Item and Dependency Mapping  \nL54:     *  Multi-File Code Generation  \nL55:     *  PII Data Sanitization  \nL56:   * \nL57: \nL58:  CLI Reference   \nL59: \nL60: CLI Reference \nL61:     *  Finetuning GPT-3.5  \nL62:     *  Usage Tracking  \nL63:   *    API Reference  API Reference \nL64:     *  Core Library  \nL65:   * \nL66: \nL67:  Blog   \nL68: \nL69: Blog \nL70:     *    Archive  Archive \nL71:       *  2023  \nL72: \nL73: Table of contents \nL74: \nL75:   *  Usage  \nL76:   *  Installation  \nL77:   *  Quick Start  \nL78:     *  Step 1: Patch the client  \nL79:     *  Step 2: Define the Pydantic Model  \nL80:     *  Step 3: Extract  \nL81:   *  Pydantic Validation  \nL82:   *  Reask on validation error  \nL83:   *  License  \nL84: \nL85:     \nL86: \nL87: # Getting Started with Instructor¶\nL88: \nL89: Structured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\nL90: \nL91: * * *\nL92: \nL93: Star us on Github!.\nL94: \nL95: [Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\nL96: \nL97: Built to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.\nL98: \nL99: ## Usage¶\nL100: \nL101:     from openai import OpenAI\nL102:     import instructor\nL103: \nL104:     # Enables `response_model`\nL105:     client = instructor.patch(OpenAI())\nL106: \nL107:     class UserDetail(BaseModel):\nL108:         name: str\nL109:         age: int\nL110: \nL111:     user = client.chat.completions.create(\nL112:         model=\"gpt-3.5-turbo\",\nL113:         response_model=UserDetail,\nL114:         messages=[\nL115:             {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\nL116:         ]\nL117:     )\nL118: \nL119:     assert isinstance(user, UserDetail)\nL120:     assert user.name == \"Jason\"\nL121:     assert user.age == 25\nL122: \nL123: Using `openai\u003c1.0.0`\nL124: \nL125: If you're using `openai\u003c1.0.0` then make sure you `pip install instructor\u003c0.3.0` where you can patch a global client like so:\nL126: \nL127:     import openai\nL128:     import instructor\nL129: \nL130:     instructor.patch()\nL131: \nL132:     user = openai.ChatCompletion.create(\nL133:         ...,\nL134:         response_model=UserDetail,\nL135:     )\nL136: \nL137: Using async clients\nL138: \nL139: For async clients you must use apatch vs patch like so:\nL140: \nL141:     import instructor\nL142:     from openai import AsyncOpenAI\nL143: \nL144:     aclient = instructor.apatch(AsyncOpenAI())\nL145: \nL146:     class UserExtract(BaseModel):\nL147:         name: str\nL148:         age: int\nL149: \nL150:     model = await aclient.chat.completions.create(\nL151:         model=\"gpt-3.5-turbo\",\nL152:         response_model=UserExtract,\nL153:         messages=[\nL154:             {\"role\": \"user\", \"content\": \"Extract jason is 25 years old\"},\nL155:         ],\nL156:     )\nL157: \nL158:     assert isinstance(model, UserExtract)\nL159: \nL160: ## Installation¶\nL161: \nL162: To get started you need to install it using `pip`. Run the following command in your terminal:\nL163: \nL164:     $ pip install instructor\nL165: \nL166: ## Quick Start¶\nL167: \nL168: To simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\nL169: \nL170:   1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\nL171:   2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\nL172:   3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.\nL173: \nL174: Using Validators\nL175: \nL176: Learn more about validators checkout our blog post Good llm validation is just good validation\nL177: \nL178: ### Step 1: Patch the client¶\nL179: \nL180: First, import the required libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter.\nL181: \nL182:     import instructor\nL183:     from openai import OpenAI\nL184:     from pydantic import BaseModel\nL185: \nL186:     # This enables response_model keyword\nL187:     # from client.chat.completions.create\nL188:     client = instructor.patch(OpenAI())\nL189: \nL190: ### Step 2: Define the Pydantic Model¶\nL191: \nL192: Create a Pydantic model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.\nL193: \nL194:     from pydantic import BaseModel\nL195: \nL196:     class UserDetail(BaseModel):\nL197:         name: str\nL198:         age: int\nL199: \nL200: ### Step 3: Extract¶\nL201\nVisible: 0% - 64%"}]},"command":"open_url","args":["https://jxnl.github.io/instructor/"],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"e30e2d6f-a394-4df3-a783-313ed23f477b","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"e30e2d6f-a394-4df3-a783-313ed23f477b","children":["06727e48-6085-4ff8-8ac2-890d2041f492"]},"e30e2d6f-a394-4df3-a783-313ed23f477b":{"id":"e30e2d6f-a394-4df3-a783-313ed23f477b","message":{"id":"e30e2d6f-a394-4df3-a783-313ed23f477b","author":{"role":"assistant","metadata":{}},"create_time":1700092075.059889,"content":{"content_type":"code","language":"unknown","text":"open_url(\"https://jxnl.github.io/instructor/\")"},"status":"finished_successfully","end_turn":false,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100265]},"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"browser"},"parent":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","children":["4557cc9e-fef2-4ab0-8369-67ab695beaea"]},"aaa22b8c-2f45-455a-bce9-25bf72220bf6":{"id":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","message":{"id":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","author":{"role":"user","metadata":{}},"create_time":1700092033.677074,"content":{"content_type":"text","parts":["improve this page https://jxnl.github.io/instructor/"]},"status":"finished_successfully","weight":1,"metadata":{"timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"403dec8e-dd1a-4c60-be0c-a3c964091e7e","children":["e30e2d6f-a394-4df3-a783-313ed23f477b"]},"403dec8e-dd1a-4c60-be0c-a3c964091e7e":{"id":"403dec8e-dd1a-4c60-be0c-a3c964091e7e","message":{"id":"403dec8e-dd1a-4c60-be0c-a3c964091e7e","author":{"role":"system","metadata":{}},"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","weight":1,"metadata":{"shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063","is_visually_hidden_from_conversation":true},"recipient":"all"},"parent":"991d246d-6ea1-4f6c-a309-d71407c515b8","children":["aaa22b8c-2f45-455a-bce9-25bf72220bf6"]},"991d246d-6ea1-4f6c-a309-d71407c515b8":{"id":"991d246d-6ea1-4f6c-a309-d71407c515b8","message":{"id":"991d246d-6ea1-4f6c-a309-d71407c515b8","author":{"role":"system","metadata":{}},"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0,"metadata":{"shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063","is_visually_hidden_from_conversation":true},"recipient":"all"},"parent":"aaa1c82e-4051-4835-9fa3-85ccff28d684","children":["403dec8e-dd1a-4c60-be0c-a3c964091e7e"]},"aaa1c82e-4051-4835-9fa3-85ccff28d684":{"id":"aaa1c82e-4051-4835-9fa3-85ccff28d684","children":["991d246d-6ea1-4f6c-a309-d71407c515b8"]}},"moderation_results":[],"current_node":"cbcf902d-5adc-4bc0-bdf2-996da301ad65","conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063","conversation_template_id":"g-8iui73B2J","gizmo_id":"g-8iui73B2J","is_archived":false,"safe_urls":["jxnl.github.io","https://jxnl.github.io/instructor/"],"is_public":true,"linear_conversation":[{"id":"aaa1c82e-4051-4835-9fa3-85ccff28d684","children":["991d246d-6ea1-4f6c-a309-d71407c515b8"]},{"id":"991d246d-6ea1-4f6c-a309-d71407c515b8","message":{"id":"991d246d-6ea1-4f6c-a309-d71407c515b8","author":{"role":"system","metadata":{}},"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","end_turn":true,"weight":0,"metadata":{"shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063","is_visually_hidden_from_conversation":true},"recipient":"all"},"parent":"aaa1c82e-4051-4835-9fa3-85ccff28d684","children":["403dec8e-dd1a-4c60-be0c-a3c964091e7e"]},{"id":"403dec8e-dd1a-4c60-be0c-a3c964091e7e","message":{"id":"403dec8e-dd1a-4c60-be0c-a3c964091e7e","author":{"role":"system","metadata":{}},"content":{"content_type":"text","parts":[""]},"status":"finished_successfully","weight":1,"metadata":{"shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063","is_visually_hidden_from_conversation":true},"recipient":"all"},"parent":"991d246d-6ea1-4f6c-a309-d71407c515b8","children":["aaa22b8c-2f45-455a-bce9-25bf72220bf6"]},{"id":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","message":{"id":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","author":{"role":"user","metadata":{}},"create_time":1700092033.677074,"content":{"content_type":"text","parts":["improve this page https://jxnl.github.io/instructor/"]},"status":"finished_successfully","weight":1,"metadata":{"timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"403dec8e-dd1a-4c60-be0c-a3c964091e7e","children":["e30e2d6f-a394-4df3-a783-313ed23f477b"]},{"id":"e30e2d6f-a394-4df3-a783-313ed23f477b","message":{"id":"e30e2d6f-a394-4df3-a783-313ed23f477b","author":{"role":"assistant","metadata":{}},"create_time":1700092075.059889,"content":{"content_type":"code","language":"unknown","text":"open_url(\"https://jxnl.github.io/instructor/\")"},"status":"finished_successfully","end_turn":false,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100265]},"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"browser"},"parent":"aaa22b8c-2f45-455a-bce9-25bf72220bf6","children":["4557cc9e-fef2-4ab0-8369-67ab695beaea"]},{"id":"4557cc9e-fef2-4ab0-8369-67ab695beaea","message":{"id":"4557cc9e-fef2-4ab0-8369-67ab695beaea","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.061035,"content":{"content_type":"tether_browsing_display","result":"L0: \nL1: URL: https://jxnl.github.io/instructor/\nL2:  \nL3: \nL4: 【0† Skip to content 】 \nL5: \nL6: 【1† 】 \nL7: \nL8: Instructor (openai_function_call) \nL9: \nL10: Quick Start \nL11: \nL12:   【2† †javascript:void(0)】 \nL13: \nL14: Initializing search \nL15: \nL16: 【3† instructor †github.com】 \nL17: \nL18:   * 【1† Introduction 】 \nL19:   * 【4† Cookbook 】 \nL20:   * 【5† CLI Reference 】 \nL21:   * 【6† API Reference 】 \nL22:   * 【7† Blog 】 \nL23: \nL24: 【1† 】 Instructor (openai_function_call) \nL25: \nL26: 【3† instructor †github.com】 \nL27: \nL28:   * \nL29: \nL30: 【1† Introduction 】  \nL31: \nL32: Introduction \nL33:     * 【8† Validators 】 \nL34:     * 【9† Distillation 】 \nL35:     * 【10† Prompt Engineering Tips 】 \nL36:     * 【11† Philosophy 】 \nL37:   * \nL38: \nL39: 【4† Cookbook 】  \nL40: \nL41: Cookbook \nL42:     * 【12† Streaming Lists 】 \nL43:     * 【13† Handling Missing Content 】 \nL44:     * 【14† Text Classification 】 \nL45:     * 【15† Self Critique 】 \nL46:     * 【16† Citations 】 \nL47:     * 【17† Knowledge Graph 】 \nL48:     * 【18† Entity Resolution 】 \nL49:     * 【19† Search Queries 】 \nL50:     * 【20† Query Decomposition 】 \nL51:     * 【21† Recursive Schemas 】 \nL52:     * 【22† Table Extraction 】 \nL53:     * 【23† Action Item and Dependency Mapping 】 \nL54:     * 【24† Multi-File Code Generation 】 \nL55:     * 【25† PII Data Sanitization 】 \nL56:   * \nL57: \nL58: 【5† CLI Reference 】  \nL59: \nL60: CLI Reference \nL61:     * 【26† Finetuning GPT-3.5 】 \nL62:     * 【27† Usage Tracking 】 \nL63:   *    API Reference  API Reference \nL64:     * 【6† Core Library 】 \nL65:   * \nL66: \nL67: 【7† Blog 】  \nL68: \nL69: Blog \nL70:     *    Archive  Archive \nL71:       * 【28† 2023 】 \nL72: \nL73: Table of contents \nL74: \nL75:   * 【29† Usage 】 \nL76:   * 【30† Installation 】 \nL77:   * 【31† Quick Start 】 \nL78:     * 【32† Step 1: Patch the client 】 \nL79:     * 【33† Step 2: Define the Pydantic Model 】 \nL80:     * 【34† Step 3: Extract 】 \nL81:   * 【35† Pydantic Validation 】 \nL82:   * 【36† Reask on validation error 】 \nL83:   * 【37† License 】 \nL84: \nL85: 【38† †github.com】 【39† †github.com】 \nL86: \nL87: # Getting Started with Instructor【0†¶】\nL88: \nL89: Structured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\nL90: \nL91: * * *\nL92: \nL93: 【40†Star us on Github!】.\nL94: \nL95: [Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\nL96: \nL97: Built to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.\nL98: \nL99: ## Usage【29†¶】\nL100: \nL101:     from openai import OpenAI\nL102:     import instructor\nL103: \nL104:     # Enables `response_model`\nL105:     client = instructor.patch(OpenAI())\nL106: \nL107:     class UserDetail(BaseModel):\nL108:         name: str\nL109:         age: int\nL110: \nL111:     user = client.chat.completions.create(\nL112:         model=\"gpt-3.5-turbo\",\nL113:         response_model=UserDetail,\nL114:         messages=[\nL115:             {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\nL116:         ]\nL117:     )\nL118: \nL119:     assert isinstance(user, UserDetail)\nL120:     assert user.name == \"Jason\"\nL121:     assert user.age == 25\nL122: \nL123: Using `openai\u003c1.0.0`\nL124: \nL125: If you're using `openai\u003c1.0.0` then make sure you `pip install instructor\u003c0.3.0` where you can patch a global client like so:\nL126: \nL127:     import openai\nL128:     import instructor\nL129: \nL130:     instructor.patch()\nL131: \nL132:     user = openai.ChatCompletion.create(\nL133:         ...,\nL134:         response_model=UserDetail,\nL135:     )\nL136: \nL137: Using async clients\nL138: \nL139: For async clients you must use apatch vs patch like so:\nL140: \nL141:     import instructor\nL142:     from openai import AsyncOpenAI\nL143: \nL144:     aclient = instructor.apatch(AsyncOpenAI())\nL145: \nL146:     class UserExtract(BaseModel):\nL147:         name: str\nL148:         age: int\nL149: \nL150:     model = await aclient.chat.completions.create(\nL151:         model=\"gpt-3.5-turbo\",\nL152:         response_model=UserExtract,\nL153:         messages=[\nL154:             {\"role\": \"user\", \"content\": \"Extract jason is 25 years old\"},\nL155:         ],\nL156:     )\nL157: \nL158:     assert isinstance(model, UserExtract)\nL159: \nL160: ## Installation【30†¶】\nL161: \nL162: To get started you need to install it using `pip`. Run the following command in your terminal:\nL163: \nL164:     $ pip install instructor\nL165: \nL166: ## Quick Start【31†¶】\nL167: \nL168: To simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\nL169: \nL170:   1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\nL171:   2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\nL172:   3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.\nL173: \nL174: Using Validators\nL175: \nL176: Learn more about validators checkout our blog post 【41†Good llm validation is just good validation】\nL177: \nL178: ### Step 1: Patch the client【32†¶】\nL179: \nL180: First, import the required libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter.\nL181: \nL182:     import instructor\nL183:     from openai import OpenAI\nL184:     from pydantic import BaseModel\nL185: \nL186:     # This enables response_model keyword\nL187:     # from client.chat.completions.create\nL188:     client = instructor.patch(OpenAI())\nL189: \nL190: ### Step 2: Define the Pydantic Model【33†¶】\nL191: \nL192: Create a Pydantic model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.\nL193: \nL194:     from pydantic import BaseModel\nL195: \nL196:     class UserDetail(BaseModel):\nL197:         name: str\nL198:         age: int\nL199: \nL200: ### Step 3: Extract【34†¶】\nL201\nVisible: 0% - 64%","summary":"Quick Start - Instructor (openai_function_call) (jxnl.github.io)\n","assets":[]},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"L0: \nL1: URL: https://jxnl.github.io/instructor/\nL2:  \nL3: \nL4:  Skip to content  \nL5: \nL6:   \nL7: \nL8: Instructor (openai_function_call) \nL9: \nL10: Quick Start \nL11: \nL12:     \nL13: \nL14: Initializing search \nL15: \nL16:  instructor  \nL17: \nL18:   *  Introduction  \nL19:   *  Cookbook  \nL20:   *  CLI Reference  \nL21:   *  API Reference  \nL22:   *  Blog  \nL23: \nL24:   Instructor (openai_function_call) \nL25: \nL26:  instructor  \nL27: \nL28:   * \nL29: \nL30:  Introduction   \nL31: \nL32: Introduction \nL33:     *  Validators  \nL34:     *  Distillation  \nL35:     *  Prompt Engineering Tips  \nL36:     *  Philosophy  \nL37:   * \nL38: \nL39:  Cookbook   \nL40: \nL41: Cookbook \nL42:     *  Streaming Lists  \nL43:     *  Handling Missing Content  \nL44:     *  Text Classification  \nL45:     *  Self Critique  \nL46:     *  Citations  \nL47:     *  Knowledge Graph  \nL48:     *  Entity Resolution  \nL49:     *  Search Queries  \nL50:     *  Query Decomposition  \nL51:     *  Recursive Schemas  \nL52:     *  Table Extraction  \nL53:     *  Action Item and Dependency Mapping  \nL54:     *  Multi-File Code Generation  \nL55:     *  PII Data Sanitization  \nL56:   * \nL57: \nL58:  CLI Reference   \nL59: \nL60: CLI Reference \nL61:     *  Finetuning GPT-3.5  \nL62:     *  Usage Tracking  \nL63:   *    API Reference  API Reference \nL64:     *  Core Library  \nL65:   * \nL66: \nL67:  Blog   \nL68: \nL69: Blog \nL70:     *    Archive  Archive \nL71:       *  2023  \nL72: \nL73: Table of contents \nL74: \nL75:   *  Usage  \nL76:   *  Installation  \nL77:   *  Quick Start  \nL78:     *  Step 1: Patch the client  \nL79:     *  Step 2: Define the Pydantic Model  \nL80:     *  Step 3: Extract  \nL81:   *  Pydantic Validation  \nL82:   *  Reask on validation error  \nL83:   *  License  \nL84: \nL85:     \nL86: \nL87: # Getting Started with Instructor¶\nL88: \nL89: Structured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\nL90: \nL91: * * *\nL92: \nL93: Star us on Github!.\nL94: \nL95: [Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\nL96: \nL97: Built to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.\nL98: \nL99: ## Usage¶\nL100: \nL101:     from openai import OpenAI\nL102:     import instructor\nL103: \nL104:     # Enables `response_model`\nL105:     client = instructor.patch(OpenAI())\nL106: \nL107:     class UserDetail(BaseModel):\nL108:         name: str\nL109:         age: int\nL110: \nL111:     user = client.chat.completions.create(\nL112:         model=\"gpt-3.5-turbo\",\nL113:         response_model=UserDetail,\nL114:         messages=[\nL115:             {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\nL116:         ]\nL117:     )\nL118: \nL119:     assert isinstance(user, UserDetail)\nL120:     assert user.name == \"Jason\"\nL121:     assert user.age == 25\nL122: \nL123: Using `openai\u003c1.0.0`\nL124: \nL125: If you're using `openai\u003c1.0.0` then make sure you `pip install instructor\u003c0.3.0` where you can patch a global client like so:\nL126: \nL127:     import openai\nL128:     import instructor\nL129: \nL130:     instructor.patch()\nL131: \nL132:     user = openai.ChatCompletion.create(\nL133:         ...,\nL134:         response_model=UserDetail,\nL135:     )\nL136: \nL137: Using async clients\nL138: \nL139: For async clients you must use apatch vs patch like so:\nL140: \nL141:     import instructor\nL142:     from openai import AsyncOpenAI\nL143: \nL144:     aclient = instructor.apatch(AsyncOpenAI())\nL145: \nL146:     class UserExtract(BaseModel):\nL147:         name: str\nL148:         age: int\nL149: \nL150:     model = await aclient.chat.completions.create(\nL151:         model=\"gpt-3.5-turbo\",\nL152:         response_model=UserExtract,\nL153:         messages=[\nL154:             {\"role\": \"user\", \"content\": \"Extract jason is 25 years old\"},\nL155:         ],\nL156:     )\nL157: \nL158:     assert isinstance(model, UserExtract)\nL159: \nL160: ## Installation¶\nL161: \nL162: To get started you need to install it using `pip`. Run the following command in your terminal:\nL163: \nL164:     $ pip install instructor\nL165: \nL166: ## Quick Start¶\nL167: \nL168: To simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\nL169: \nL170:   1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\nL171:   2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\nL172:   3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.\nL173: \nL174: Using Validators\nL175: \nL176: Learn more about validators checkout our blog post Good llm validation is just good validation\nL177: \nL178: ### Step 1: Patch the client¶\nL179: \nL180: First, import the required libraries and apply the patch function to the OpenAI module. This exposes new functionality with the response_model parameter.\nL181: \nL182:     import instructor\nL183:     from openai import OpenAI\nL184:     from pydantic import BaseModel\nL185: \nL186:     # This enables response_model keyword\nL187:     # from client.chat.completions.create\nL188:     client = instructor.patch(OpenAI())\nL189: \nL190: ### Step 2: Define the Pydantic Model¶\nL191: \nL192: Create a Pydantic model to define the structure of the data you want to extract. This model will map directly to the information in the prompt.\nL193: \nL194:     from pydantic import BaseModel\nL195: \nL196:     class UserDetail(BaseModel):\nL197:         name: str\nL198:         age: int\nL199: \nL200: ### Step 3: Extract¶\nL201\nVisible: 0% - 64%"}]},"command":"open_url","args":["https://jxnl.github.io/instructor/"],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"e30e2d6f-a394-4df3-a783-313ed23f477b","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"e30e2d6f-a394-4df3-a783-313ed23f477b","children":["06727e48-6085-4ff8-8ac2-890d2041f492"]},{"id":"06727e48-6085-4ff8-8ac2-890d2041f492","message":{"id":"06727e48-6085-4ff8-8ac2-890d2041f492","author":{"role":"assistant","metadata":{}},"create_time":1700092075.065864,"content":{"content_type":"code","language":"unknown","text":"quote_lines(87, 97);\nquote_lines(99, 121);\nquote_lines(160, 172);"},"status":"finished_successfully","end_turn":false,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100265]},"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"4557cc9e-fef2-4ab0-8369-67ab695beaea","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"browser"},"parent":"4557cc9e-fef2-4ab0-8369-67ab695beaea","children":["084094e7-e16a-45dd-a583-e750645fb844"]},{"id":"084094e7-e16a-45dd-a583-e750645fb844","message":{"id":"084094e7-e16a-45dd-a583-e750645fb844","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.070938,"content":{"content_type":"tether_quote","url":"https://jxnl.github.io/instructor/","domain":"jxnl.github.io","text":"# Getting Started with Instructor【0†¶】\n\nStructured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\n\n* * *\n\n【40†Star us on Github!】.\n\n[Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\n\nBuilt to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.","title":"Quick Start - Instructor (openai_function_call)"},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"# Getting Started with Instructor【0†¶】\n\nStructured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\n\n* * *\n\n【40†Star us on Github!】.\n\n[Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\n\nBuilt to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts."}]},"command":"quote_lines","args":[87,97],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"06727e48-6085-4ff8-8ac2-890d2041f492","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"06727e48-6085-4ff8-8ac2-890d2041f492","children":["b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d"]},{"id":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","message":{"id":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.074878,"content":{"content_type":"tether_quote","url":"https://jxnl.github.io/instructor/","domain":"jxnl.github.io","text":"## Usage【29†¶】\n\n    from openai import OpenAI\n    import instructor\n\n    # Enables `response_model`\n    client = instructor.patch(OpenAI())\n\n    class UserDetail(BaseModel):\n        name: str\n        age: int\n\n    user = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n        ]\n    )\n\n    assert isinstance(user, UserDetail)\n    assert user.name == \"Jason\"\n    assert user.age == 25","title":"Quick Start - Instructor (openai_function_call)"},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Usage【29†¶】\n\n    from openai import OpenAI\n    import instructor\n\n    # Enables `response_model`\n    client = instructor.patch(OpenAI())\n\n    class UserDetail(BaseModel):\n        name: str\n        age: int\n\n    user = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n        ]\n    )\n\n    assert isinstance(user, UserDetail)\n    assert user.name == \"Jason\"\n    assert user.age == 25"}]},"command":"quote_lines","args":[99,121],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"084094e7-e16a-45dd-a583-e750645fb844","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"084094e7-e16a-45dd-a583-e750645fb844","children":["fbf0a063-f51c-4570-89db-be2b180d6887"]},{"id":"fbf0a063-f51c-4570-89db-be2b180d6887","message":{"id":"fbf0a063-f51c-4570-89db-be2b180d6887","author":{"role":"tool","name":"browser","metadata":{}},"create_time":1700092075.079015,"content":{"content_type":"tether_quote","url":"https://jxnl.github.io/instructor/","domain":"jxnl.github.io","text":"## Installation【30†¶】\n\nTo get started you need to install it using `pip`. Run the following command in your terminal:\n\n    $ pip install instructor\n\n## Quick Start【31†¶】\n\nTo simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\n\n  1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\n  2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\n  3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.","title":"Quick Start - Instructor (openai_function_call)"},"status":"finished_successfully","weight":0,"metadata":{"_cite_metadata":{"citation_format":{"name":"tether_og"},"metadata_list":[{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Installation【30†¶】\n\nTo get started you need to install it using `pip`. Run the following command in your terminal:\n\n    $ pip install instructor\n\n## Quick Start【31†¶】\n\nTo simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\n\n  1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\n  2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\n  3. The `validation_context` parameter, which allows you to specify a context object that validators have access to."}]},"command":"quote_lines","args":[160,172],"status":"finished","is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"b5e503ac-8dd4-44ac-b1b4-e4eaf61ea83d","children":["a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3"]},{"id":"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3","message":{"id":"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3","author":{"role":"assistant","metadata":{}},"create_time":1700092075.083032,"content":{"content_type":"text","parts":["The Instructor page you shared is a documentation site for a Python package that facilitates structured data extraction using OpenAI's function calling API. It's designed for simplicity, transparency, and control, and is built specifically to interact with OpenAI's API from Python, aiming to be intuitive and easy to use【7†source】.\n\nTo improve this page, consider the following:\n\n1. **User Experience and Design**: The page layout is straightforward, but it could benefit from a more engaging design. Adding interactive elements, like collapsible sections for different topics, or a search function to quickly find relevant information, would enhance the user experience.\n\n2. **Content Clarity**: The current content, such as usage examples【8†source】 and installation instructions【9†source】, is clear but could be expanded. More comprehensive examples covering a variety of use cases, detailed explanations of the functions, and potential error handling could make the documentation more robust.\n\n3. **Accessibility and Readability**: Ensure that the text is easily readable, with a good contrast between the background and text colors. Using larger fonts and headers can also make the content more accessible.\n\n4. **Interactive Code Examples**: Interactive code snippets that users can edit and run directly on the page can be a powerful way to demonstrate the capabilities of the Instructor package.\n\n5. **Community Engagement**: Encouraging community contributions through GitHub or a dedicated forum can foster a collaborative environment. Featuring a section for community-contributed tips, tricks, and use cases would be beneficial.\n\n6. **SEO Optimization**: To increase the visibility of the page, consider implementing SEO best practices, such as keyword optimization, meta descriptions, and alt text for images.\n\n7. **Mobile Responsiveness**: Ensuring the page is fully responsive and looks good on various devices, including tablets and smartphones, is crucial in today's mobile-first world.\n\n8. **Feedback Mechanism**: Incorporating a feedback mechanism, like a simple form or comment section, can provide valuable insights from users and help in making continuous improvements.\n\nRemember, the key is to balance technical depth with ease of understanding, making the documentation both informative and approachable for users with different levels of expertise."]},"status":"finished_successfully","end_turn":true,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100260]},"citations":[{"start_ix":321,"end_ix":331,"citation_format_type":"tether_og","metadata":{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"# Getting Started with Instructor【0†¶】\n\nStructured extraction in Python, powered by OpenAI's function calling api, designed for simplicity, transparency, and control.\n\n* * *\n\n【40†Star us on Github!】.\n\n[Image 0: Buy Me a Coffee] [Image 1: Twitter Follow] [Image 2: Downloads] [Image 3: GitHub stars]\n\nBuilt to interact solely with openai's function calling api from python. It's designed to be intuitive, easy to use, and provide great visibility into your prompts.","extra":{"cited_message_idx":7,"evidence_text":"source"}}},{"start_ix":741,"end_ix":751,"citation_format_type":"tether_og","metadata":{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Usage【29†¶】\n\n    from openai import OpenAI\n    import instructor\n\n    # Enables `response_model`\n    client = instructor.patch(OpenAI())\n\n    class UserDetail(BaseModel):\n        name: str\n        age: int\n\n    user = client.chat.completions.create(\n        model=\"gpt-3.5-turbo\",\n        response_model=UserDetail,\n        messages=[\n            {\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"},\n        ]\n    )\n\n    assert isinstance(user, UserDetail)\n    assert user.name == \"Jason\"\n    assert user.age == 25","extra":{"cited_message_idx":8,"evidence_text":"source"}}},{"start_ix":781,"end_ix":791,"citation_format_type":"tether_og","metadata":{"type":"webpage","title":"Quick Start - Instructor (openai_function_call)","url":"https://jxnl.github.io/instructor/","text":"## Installation【30†¶】\n\nTo get started you need to install it using `pip`. Run the following command in your terminal:\n\n    $ pip install instructor\n\n## Quick Start【31†¶】\n\nTo simplify your work with OpenAI we offer a patching mechanism for the `ChatCompletion` class. The patch introduces 3 features to the `ChatCompletion` class:\n\n  1. The `response_model` parameter, which allows you to specify a Pydantic model to extract data into.\n  2. The `max_retries` parameter, which allows you to specify the number of times to retry the request if it fails.\n  3. The `validation_context` parameter, which allows you to specify a context object that validators have access to.","extra":{"cited_message_idx":9,"evidence_text":"source"}}}],"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"fbf0a063-f51c-4570-89db-be2b180d6887","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"fbf0a063-f51c-4570-89db-be2b180d6887","children":["aaa21873-cfb5-42e1-ab3e-d81b714f99ce"]},{"id":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","message":{"id":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","author":{"role":"user","metadata":{}},"create_time":1700092123.736646,"content":{"content_type":"text","parts":["give me a sample of the prose rewritten"]},"status":"finished_successfully","weight":1,"metadata":{"timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"a0bc2904-c1df-404d-bf5a-cec6aa4c5ff3","children":["cbcf902d-5adc-4bc0-bdf2-996da301ad65"]},{"id":"cbcf902d-5adc-4bc0-bdf2-996da301ad65","message":{"id":"cbcf902d-5adc-4bc0-bdf2-996da301ad65","author":{"role":"assistant","metadata":{}},"create_time":1700092162.250364,"content":{"content_type":"text","parts":["Certainly! Here's a rewritten sample of the prose for the Instructor page, focusing on user-friendliness and clarity:\n\n---\n\n**Welcome to Instructor - Your Gateway to Streamlined Data Extraction with OpenAI**\n\nDive into the world of Python-based structured extraction, empowered by OpenAI's cutting-edge function calling API. Instructor stands out for its simplicity, transparency, and user-centric design. Whether you're a seasoned developer or just starting out, you'll find Instructor's approach intuitive and its results insightful.\n\n**Get Started in Moments**\n\nInstalling Instructor is a breeze. Just run `pip install instructor` in your terminal and you're on your way to a smoother data handling experience.\n\n**How Instructor Enhances Your Workflow**\n\nOur patch for the `ChatCompletion` class introduces three key enhancements:\n\n1. **Response Model**: Specify a Pydantic model to streamline data extraction.\n2. **Max Retries**: Set your desired number of retry attempts for requests.\n3. **Validation Context**: Provide a context object for enhanced validator access.\n\n**A Glimpse into Instructor's Capabilities**\n\nWith Instructor, your code becomes more efficient and readable. Here’s a quick peek:\n\n```python\nfrom openai import OpenAI\nimport instructor\n\nclient = instructor.patch(OpenAI())\n\n# Define a user detail model\nclass UserDetail(BaseModel):\n    name: str\n    age: int\n\n# Extract user details with ease\nuser = client.chat.completions.create(\n    model=\"gpt-3.5-turbo\",\n    response_model=UserDetail,\n    messages=[{\"role\": \"user\", \"content\": \"Extract Jason is 25 years old\"}]\n)\n\nassert isinstance(user, UserDetail)\nassert user.name == \"Jason\"\nassert user.age == 25\n```\n\n**Engage, Explore, Excel**\n\nYour journey with Instructor doesn't end with code. Join our GitHub community, share your experiences, and grow with fellow enthusiasts. Together, let's redefine the possibilities of Python and OpenAI.\n\n---\n\nThis revised version focuses on making the information more engaging and easier to digest, with clear section headers and an inviting tone."]},"status":"finished_successfully","end_turn":true,"weight":1,"metadata":{"finish_details":{"type":"stop","stop_tokens":[100260]},"is_complete":true,"model_slug":"gpt-4-gizmo","parent_id":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","timestamp_":"absolute","shared_conversation_id":"51b5e459-6956-4591-b8a9-beeae0401063"},"recipient":"all"},"parent":"aaa21873-cfb5-42e1-ab3e-d81b714f99ce","children":[]}],"has_user_editable_context":false,"continue_conversation_url":"https://chat.openai.com/share/51b5e459-6956-4591-b8a9-beeae0401063/continue","moderation_state":{"has_been_moderated":false,"has_been_blocked":false,"has_been_accepted":false,"has_been_auto_blocked":false,"has_been_auto_moderated":false}}},"continueMode":false,"moderationMode":false,"plugins":null,"chatPageProps":{"user":{"id":"user-DiQTGiGVFqze6dprFzmFn9HU","name":"Daniel Ogenrwot","email":"ogenrwot@unlv.nevada.edu","image":"https://lh3.googleusercontent.com/a/ACg8ocJs3eXuKK9Cvxw--rhfLSyMa7t75KLFfn8RZjuspp7ofw=s96-c","picture":"https://lh3.googleusercontent.com/a/ACg8ocJs3eXuKK9Cvxw--rhfLSyMa7t75KLFfn8RZjuspp7ofw=s96-c","idp":"google-oauth2","iat":1704763431,"mfa":false,"groups":[],"intercom_hash":"b1696c9b7c3e106e5e1562cebe511d91a2b7ecaada4affd27e426cd79ce86e2f"},"serviceStatus":{},"serviceAnnouncement":{"public":{},"paid":{}},"cfConnectingIp":"2600:8801:359a:b200:10b1:c381:2196:e960","statsig":{"payload":{"feature_gates":{"mC7arE5IsSMGuGv+JtQNn6PkLNjGMgnPGm4lNwCVcd4=":{"name":"mC7arE5IsSMGuGv+JtQNn6PkLNjGMgnPGm4lNwCVcd4=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:chatgpt_voice_team","gateValue":"false","ruleID":"default"}]},"4bxrZiqrvUhz7pNmrq7/hje8GGth3CK38a+UCoGT55w=":{"name":"4bxrZiqrvUhz7pNmrq7/hje8GGth3CK38a+UCoGT55w=","value":false,"rule_id":"6Usmt3Th0mkUkVQJ0oyeST:0.00:1","secondary_exposures":[]},"BwgqaCydMQQ3DfMuT3le70YG2UMR90ZQUizkz8s87Og=":{"name":"BwgqaCydMQQ3DfMuT3le70YG2UMR90ZQUizkz8s87Og=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:chatgpt_voice_team","gateValue":"false","ruleID":"default"}]},"sB09rxeNC0dm+q105n4ilqzJPvZ+fb8Adgn7dgHyAJs=":{"name":"sB09rxeNC0dm+q105n4ilqzJPvZ+fb8Adgn7dgHyAJs=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:chatgpt_voice_team","gateValue":"false","ruleID":"default"}]},"/sqBSo8CbSfm33mGuPq/xK+GiRwPnbT26mPKmQkikn4=":{"name":"/sqBSo8CbSfm33mGuPq/xK+GiRwPnbT26mPKmQkikn4=","value":false,"rule_id":"default","secondary_exposures":[]},"8YdWfy6BaXA6MDnlnTc17AwNRhxQ4rcfy5G+sYaHQ/A=":{"name":"8YdWfy6BaXA6MDnlnTc17AwNRhxQ4rcfy5G+sYaHQ/A=","value":false,"rule_id":"63qNN95X7P6VSHVff2nL76","secondary_exposures":[]},"9frMP2Uapo9+GZFF/eyDv3qypmVGR3bBx7kQxlUjFL0=":{"name":"9frMP2Uapo9+GZFF/eyDv3qypmVGR3bBx7kQxlUjFL0=","value":false,"rule_id":"4Cs7bnD6u8s4FIa2CdgJ7i","secondary_exposures":[]},"zP79mMrzyNTmUIk4BvnRSRf1QyskcWqpVbgx/DuBSlk=":{"name":"zP79mMrzyNTmUIk4BvnRSRf1QyskcWqpVbgx/DuBSlk=","value":false,"rule_id":"default","secondary_exposures":[]},"G4FKkwqOMLlLXCjFizXkc6Fbyds7IQgmeDgcOnlzXcc=":{"name":"G4FKkwqOMLlLXCjFizXkc6Fbyds7IQgmeDgcOnlzXcc=","value":false,"rule_id":"default","secondary_exposures":[]},"Ot01tCFiILXHbMzQliq1LFtcH9p484nys9JQ3jNBBSc=":{"name":"Ot01tCFiILXHbMzQliq1LFtcH9p484nys9JQ3jNBBSc=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:european_legal_restricted","gateValue":"false","ruleID":"default"}]},"ZB1N+sYIfld1iUD73LMNp+7PHtb5fjkv1Fqd9stCmhM=":{"name":"ZB1N+sYIfld1iUD73LMNp+7PHtb5fjkv1Fqd9stCmhM=","value":false,"rule_id":"default","secondary_exposures":[]},"AmHQM8fzcDgvtrUTWfKdHeeC+liSx6Ap3mIjS2v2T7k=":{"name":"AmHQM8fzcDgvtrUTWfKdHeeC+liSx6Ap3mIjS2v2T7k=","value":false,"rule_id":"1IdfApkb0f3RHjOg804mYI:5.00:5","secondary_exposures":[]},"v6yV8GS0zH+VdEey3WZ8OCkuXSPit1tWZ1w5XGJKgwU=":{"name":"v6yV8GS0zH+VdEey3WZ8OCkuXSPit1tWZ1w5XGJKgwU=","value":true,"rule_id":"VNBdYfNSNNUyDdMpaiaZ9:100.00:1","secondary_exposures":[]},"bZIChv8u2y59nAdcmf3Sxu+c4LOtTeRmbLn99GUUOrQ=":{"name":"bZIChv8u2y59nAdcmf3Sxu+c4LOtTeRmbLn99GUUOrQ=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:gizmo_store_team","gateValue":"false","ruleID":"default"},{"gate":"segment:memory_team","gateValue":"false","ruleID":"default"}]},"NFLu/8gcH3+m9yHiY/kPxE83zLFYMhk3cWVEq2zR+NM=":{"name":"NFLu/8gcH3+m9yHiY/kPxE83zLFYMhk3cWVEq2zR+NM=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"XrhPGbeUzfIBQaHMWl4/GYZzdDnDMzHb96RYes5lw2w=":{"name":"XrhPGbeUzfIBQaHMWl4/GYZzdDnDMzHb96RYes5lw2w=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"FEo7XK0f7Hn3U2RwSds2DTiEYNIpKCqrSVA2UP0BK2M=":{"name":"FEo7XK0f7Hn3U2RwSds2DTiEYNIpKCqrSVA2UP0BK2M=","value":true,"rule_id":"6sEu91zwlBGSKOqFiNpGlA:100.00:2","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"},{"gate":"segment:enterprise","gateValue":"false","ruleID":"default"},{"gate":"segment:teams_plan","gateValue":"false","ruleID":"default"}]},"9WcM78XE5AQPxf3Yv9FxM5g14rV2Sk3HsGRha1mAnxc=":{"name":"9WcM78XE5AQPxf3Yv9FxM5g14rV2Sk3HsGRha1mAnxc=","value":false,"rule_id":"default","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"+ZnfGOKTXqj/PUluVHtQHH4xXcWomraW0OeynJkthMA=":{"name":"+ZnfGOKTXqj/PUluVHtQHH4xXcWomraW0OeynJkthMA=","value":true,"rule_id":"2LpyNTIfbYC4R6XS6dfdIL","secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"}]},"a2qAmsyD94P0/7pZ6SpRYRKL9Odkp+5z2KgEZEYvsJg=":{"name":"a2qAmsyD94P0/7pZ6SpRYRKL9Odkp+5z2KgEZEYvsJg=","value":false,"rule_id":"default","secondary_exposures":[]}},"dynamic_configs":{"krxquX5lr9NsWYuE6AxcgDMKBdc3hX7WV56L3qm2h+k=":{"name":"krxquX5lr9NsWYuE6AxcgDMKBdc3hX7WV56L3qm2h+k=","value":{},"group":"default","rule_id":"default","is_device_based":false,"secondary_exposures":[{"gate":"segment:employees","gateValue":"false","ruleID":"default"},{"gate":"chatgpt-browse-sahara","gateValue":"false","ruleID":"default"}]},"Xxhhbjq3NEImgVIfGzx+Ubl6ebJS1kwRjV/2YlHJ3Zs=":{"name":"Xxhhbjq3NEImgVIfGzx+Ubl6ebJS1kwRjV/2YlHJ3Zs=","value":{"google.com":["google.com","googleapis.com","www.googleapis.com","oauth2.googleapis.com"],"microsoftonline.com":["microsoft.com","microsoftonline.com"],"adobelogin.com":["adobe.com","adobelogin.com"],"useflorian.com":["useflorian.com","convex.site"],"yahoo.com":["yahooapis.com","yahoo.com"],"app.vssps.visualstudio.com":["app.vssps.visualstudio.com","dev.azure.com"]},"group":"default","rule_id":"default","is_device_based":true,"secondary_exposures":[]},"LH4aXUWdAthHnhoeezgqr9XUAj+EyFN9/INZTPgB8Rw=":{"name":"LH4aXUWdAthHnhoeezgqr9XUAj+EyFN9/INZTPgB8Rw=","value":{},"group":"prestart","rule_id":"prestart","is_device_based":false,"secondary_exposures":[],"is_user_in_experiment":false,"is_experiment_active":false},"/NA6RKoyvTPtJS+65jbxYPRbn4zCKaPi28t+RGlIi74=":{"name":"/NA6RKoyvTPtJS+65jbxYPRbn4zCKaPi28t+RGlIi74=","value":{},"group":"prestart","rule_id":"prestart","is_device_based":false,"secondary_exposures":[],"is_user_in_experiment":false,"is_experiment_active":false},"d88zqiv5tj+jTJIQj6D5/mZRDEaFP6YEIqcwlz6Nh+8=":{"name":"d88zqiv5tj+jTJIQj6D5/mZRDEaFP6YEIqcwlz6Nh+8=","value":{},"group":"targetingGate","rule_id":"targetingGate","is_device_based":false,"secondary_exposures":[{"gate":"targeting-aa-web-240206","gateValue":"false","ruleID":"63qNN95X7P6VSHVff2nL76"}],"is_user_in_experiment":false,"is_experiment_active":true},"hxxW3hikZ7rigchg97AizJTpHbpMCwkwvbZd7t9sblc=":{"name":"hxxW3hikZ7rigchg97AizJTpHbpMCwkwvbZd7t9sblc=","value":{},"group":"targetingGate","rule_id":"targetingGate","is_device_based":false,"secondary_exposures":[{"gate":"targeting-aa-web-anon-240206","gateValue":"false","ruleID":"4Cs7bnD6u8s4FIa2CdgJ7i"}],"is_user_in_experiment":false,"is_experiment_active":true},"2gcgWHw6EUQ7WzuausBVbg88/jglfC1LmtqhBF35u2c=":{"name":"2gcgWHw6EUQ7WzuausBVbg88/jglfC1LmtqhBF35u2c=","value":{"show_new_ui":true},"group":"launchedGroup","rule_id":"launchedGroup","is_device_based":false,"secondary_exposures":[],"is_user_in_experiment":false,"is_experiment_active":false}},"layer_configs":{},"sdkParams":{},"has_updates":true,"generator":"statsig-node-sdk","time":0,"evaluated_keys":{"userID":"user-DiQTGiGVFqze6dprFzmFn9HU","customIDs":{"WebAnonymousCookieID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","DeviceId":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","stableID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093"}},"hash_used":"sha256","user_hash":"2623322862"},"user":{"country":"US","custom":{"auth_status":"logged_in","is_paid":false},"customIDs":{"WebAnonymousCookieID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","DeviceId":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093","stableID":"d05bbaf3-27d4-4fc2-bdd4-5faafc9a8093"},"ip":"2600:8801:359a:b200:10b1:c381:2196:e960","locale":"en-US","privateAttributes":{"email":"ogenrwot@unlv.nevada.edu"},"userAgent":"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36","userID":"user-DiQTGiGVFqze6dprFzmFn9HU"}},"serverPrimedAllowBrowserStorageValue":true,"showCookieConsentBanner":false,"isStorageComplianceEnabled":false,"ageVerificationDeadline":null,"ageVerificationType":"none","logOutUser":false},"isGizmoLive":true},"__N_SSP":true},"page":"/share/[[...shareParams]]","query":{"shareParams":["51b5e459-6956-4591-b8a9-beeae0401063"]},"buildId":"P9LodNv0xkZ1kyW4nyx7S","assetPrefix":"https://cdn.oaistatic.com","isFallback":false,"gssp":true,"scriptLoader":[]}</script><next-route-announcer><p aria-live="assertive" id="__next-route-announcer__" role="alert" style="border: 0px; clip: rect(0px, 0px, 0px, 0px); height: 1px; margin: -1px; overflow: hidden; padding: 0px; position: absolute; top: 0px; width: 1px; white-space: nowrap; overflow-wrap: normal;"></p></next-route-announcer><div portal-container=""><span class="pointer-events-none fixed inset-0 z-[60] mx-auto my-2 flex max-w-[560px] flex-col items-stretch justify-start md:pb-5"></span></div><iframe id="intercom-frame" style="position: absolute !important; opacity: 0 !important; width: 1px !important; height: 1px !important; top: 0 !important; left: 0 !important; border: none !important; display: block !important; z-index: -1 !important; pointer-events: none;" aria-hidden="true" tabindex="-1" title="Intercom" src="./79_files/saved_resource.html"></iframe><div class="intercom-lightweight-app"><style id="intercom-lightweight-app-style" type="text/css">
  @keyframes intercom-lightweight-app-launcher {
    from {
      opacity: 0;
      transform: scale(0.5);
    }
    to {
      opacity: 1;
      transform: scale(1);
    }
  }

  @keyframes intercom-lightweight-app-gradient {
    from {
      opacity: 0;
    }
    to {
      opacity: 1;
    }
  }

  @keyframes intercom-lightweight-app-messenger {
    0% {
      opacity: 0;
      transform: scale(0);
    }
    40% {
      opacity: 1;
    }
    100% {
      transform: scale(1);
    }
  }

  .intercom-lightweight-app {
    position: fixed;
    z-index: 2147483001;
    width: 0;
    height: 0;
    font-family: intercom-font, "Helvetica Neue", "Apple Color Emoji", Helvetica, Arial, sans-serif;
  }

  .intercom-lightweight-app-gradient {
    position: fixed;
    z-index: 2147483002;
    width: 500px;
    height: 500px;
    bottom: 0;
    right: 0;
    pointer-events: none;
    background: radial-gradient(
      ellipse at bottom right,
      rgba(29, 39, 54, 0.16) 0%,
      rgba(29, 39, 54, 0) 72%);
    animation: intercom-lightweight-app-gradient 200ms ease-out;
  }

  .intercom-lightweight-app-launcher {
    position: fixed;
    z-index: 2147483003;
    padding: 0 !important;
    margin: 0 !important;
    border: none;
    bottom: 20px;
    right: 20px;
    max-width: 48px;
    width: 48px;
    max-height: 48px;
    height: 48px;
    border-radius: 50%;
    background: #202123;
    cursor: pointer;
    box-shadow: 0 1px 6px 0 rgba(0, 0, 0, 0.06), 0 2px 32px 0 rgba(0, 0, 0, 0.16);
    transition: transform 167ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    box-sizing: content-box;
  }


  .intercom-lightweight-app-launcher:hover {
    transition: transform 250ms cubic-bezier(0.33, 0.00, 0.00, 1.00);
    transform: scale(1.1)
  }

  .intercom-lightweight-app-launcher:active {
    transform: scale(0.85);
    transition: transform 134ms cubic-bezier(0.45, 0, 0.2, 1);
  }


  .intercom-lightweight-app-launcher:focus {
    outline: none;

    
  }

  .intercom-lightweight-app-launcher-icon {
    display: flex;
    align-items: center;
    justify-content: center;
    position: absolute;
    top: 0;
    left: 0;
    width: 48px;
    height: 48px;
    transition: transform 100ms linear, opacity 80ms linear;
  }

  .intercom-lightweight-app-launcher-icon-open {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-open svg {
    width: 24px;
    height: 24px;
  }

  .intercom-lightweight-app-launcher-icon-open svg path {
    fill: rgb(255, 255, 255);
  }

  .intercom-lightweight-app-launcher-icon-self-serve {
    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg {
    height: 44px;
  }

  .intercom-lightweight-app-launcher-icon-self-serve svg path {
    fill: rgb(255, 255, 255);
  }

  .intercom-lightweight-app-launcher-custom-icon-open {
    max-height: 24px;
    max-width: 24px;

    
        opacity: 1;
        transform: rotate(0deg) scale(1);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize {
    
        opacity: 0;
        transform: rotate(-60deg) scale(0);
      
  }

  .intercom-lightweight-app-launcher-icon-minimize svg path {
    fill: rgb(255, 255, 255);
  }

  .intercom-lightweight-app-messenger {
    position: fixed;
    z-index: 2147483003;
    overflow: hidden;
    background-color: white;
    animation: intercom-lightweight-app-messenger 250ms cubic-bezier(0, 1, 1, 1);
    transform-origin: bottom right;

    
        width: 400px;
        height: calc(100% - 40px);
        max-height: 704px;
        min-height: 250px;
        right: 20px;
        bottom: 20px;
        box-shadow: 0 5px 40px rgba(0,0,0,0.16);
      

    border-radius: 16px;
  }

  .intercom-lightweight-app-messenger-header {
    height: 64px;
    border-bottom: none;
    background: #202123

    
  }

  .intercom-lightweight-app-messenger-footer{
    position:absolute;
    bottom:0;
    width: 100%;
    height: 80px;
    background: #fff;
    font-size: 14px;
    line-height: 21px;
    border-top: 1px solid rgba(0, 0, 0, 0.05);
    box-shadow: 0px 0px 25px rgba(0, 0, 0, 0.05);
    
  }

  @media print {
    .intercom-lightweight-app {
      display: none;
    }
  }
</style></div><script crossorigin="anonymous" src="./79_files/[gizmoId]-8e1c1bc7b73cf481.js"></script></body></html>